{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curious Comments \n",
    "![commentpic](comment_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A critical part of any review are the comments. We will now proceed to analyze the comments in our q data. We will judge the predictive power of these comments, and analyze the role they play in a score's q rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import os\n",
    "import math\n",
    "from itertools import chain\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by creating a dataframe of comments. We will randomly subsample 10 comments per review and only consider courses 10 or more comments. Our dataframe will consist of three columns; Comment, Course and Overall Positive Rating. A course defined to have an 'Overall Positive Rating' if it has been been given more positive ratings than negative ratings across all semesters that it has been rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIN_PER_COURSESEM_REVIEWS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_Department</th>\n",
       "      <th>C_Number</th>\n",
       "      <th>Course</th>\n",
       "      <th>C_CatNum</th>\n",
       "      <th>C_ID</th>\n",
       "      <th>C_Semester</th>\n",
       "      <th>C_Year</th>\n",
       "      <th>C_Term</th>\n",
       "      <th>C_Overall</th>\n",
       "      <th>C_Workload</th>\n",
       "      <th>C_Difficulty</th>\n",
       "      <th>C_Recommendation</th>\n",
       "      <th>C_Enrollment</th>\n",
       "      <th>C_ResponseRate</th>\n",
       "      <th>I_First</th>\n",
       "      <th>I_Last</th>\n",
       "      <th>I_ID</th>\n",
       "      <th>I_Overall</th>\n",
       "      <th>I_EffectiveLectures</th>\n",
       "      <th>I_Accessible</th>\n",
       "      <th>I_GeneratesEnthusiasm</th>\n",
       "      <th>I_EncouragesParticipation</th>\n",
       "      <th>I_UsefulFeedback</th>\n",
       "      <th>I_ReturnsAssignmentsTimely</th>\n",
       "      <th>QOverall_1</th>\n",
       "      <th>QOverall_2</th>\n",
       "      <th>QOverall_3</th>\n",
       "      <th>QOverall_4</th>\n",
       "      <th>QOverall_5</th>\n",
       "      <th>QDifficulty_1</th>\n",
       "      <th>QDifficulty_2</th>\n",
       "      <th>QDifficulty_3</th>\n",
       "      <th>QDifficulty_4</th>\n",
       "      <th>QDifficulty_5</th>\n",
       "      <th>QWorkload_1</th>\n",
       "      <th>QWorkload_2</th>\n",
       "      <th>QWorkload_3</th>\n",
       "      <th>QWorkload_4</th>\n",
       "      <th>QWorkload_5</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sem_Average</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTSCI</td>\n",
       "      <td>270</td>\n",
       "      <td>HISTSCI-270</td>\n",
       "      <td>58523</td>\n",
       "      <td>2697</td>\n",
       "      <td>Spring '12</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6</td>\n",
       "      <td>50.00</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Lemov</td>\n",
       "      <td>79de794d3e2e19eb71a2033b0ec0b76d</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'This course is a perfect example of what gr...</td>\n",
       "      <td>4.226350</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '14</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4.10</td>\n",
       "      <td>7.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50</td>\n",
       "      <td>13</td>\n",
       "      <td>76.92</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'The class has a fairly high work load, but ...</td>\n",
       "      <td>4.244370</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '13</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.20</td>\n",
       "      <td>13</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'Philosophy of the State with Dr. Chen offer...</td>\n",
       "      <td>4.256888</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '12</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>3.73</td>\n",
       "      <td>2.47</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.47</td>\n",
       "      <td>15</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.64</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'This was by far my favorite course. Dr. Che...</td>\n",
       "      <td>4.190299</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '11</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.62</td>\n",
       "      <td>13</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'Be prepared to read', u'Discussions were gr...</td>\n",
       "      <td>4.185893</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  C_Department C_Number        Course  C_CatNum  C_ID  C_Semester  C_Year  C_Term  C_Overall  C_Workload  C_Difficulty  C_Recommendation  C_Enrollment  C_ResponseRate  I_First I_Last                              I_ID  I_Overall  I_EffectiveLectures  I_Accessible  I_GeneratesEnthusiasm  I_EncouragesParticipation  I_UsefulFeedback  I_ReturnsAssignmentsTimely  QOverall_1  QOverall_2  QOverall_3  QOverall_4  QOverall_5  QDifficulty_1  QDifficulty_2  QDifficulty_3  QDifficulty_4  QDifficulty_5  \\\n",
       "0      HISTSCI      270   HISTSCI-270     58523  2697  Spring '12    2011       2       4.67        2.33          3.33              5.00             6           50.00  Rebecca  Lemov  79de794d3e2e19eb71a2033b0ec0b76d       4.67                 4.33          4.00                   4.33                       5.00              4.50                        4.00           0           0           0           1           2              0              0              2              1              0   \n",
       "1        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '14    2014       1       4.10        7.10           NaN              3.50            13           76.92     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       4.50                 4.60          3.70                   3.90                       3.90              4.10                        4.60           0           1           1           4           4              0              1              2              7              3   \n",
       "2        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '13    2013       1       3.50        2.60          3.90              3.20            13          100.00     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       3.80                 4.00          2.50                   3.50                       4.10              4.30                        4.40           0           1           1           4           4              0              1              2              7              3   \n",
       "3        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '12    2012       1       3.73        2.47          3.67              3.47            15          100.00     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       3.87                 4.33          2.64                   3.93                       4.18              3.64                        3.82           0           1           1           4           4              0              1              2              7              3   \n",
       "4        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '11    2011       1       3.85        2.00          3.54              3.62            13          100.00     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       4.08                 3.75          3.31                   3.92                       4.46              4.23                        4.08           0           1           1           4           4              0              1              2              7              3   \n",
       "\n",
       "   QWorkload_1  QWorkload_2  QWorkload_3  QWorkload_4  QWorkload_5                                           Comments  Sem_Average Positive  \n",
       "0            0            2            1            0            0  [u'This course is a perfect example of what gr...     4.226350     True  \n",
       "1            1            3            4            1            0  [u'The class has a fairly high work load, but ...     4.244370    False  \n",
       "2            1            3            4            1            0  [u'Philosophy of the State with Dr. Chen offer...     4.256888    False  \n",
       "3            1            3            4            1            0  [u'This was by far my favorite course. Dr. Che...     4.190299    False  \n",
       "4            1            3            4            1            0  [u'Be prepared to read', u'Discussions were gr...     4.185893    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdf=pd.read_csv(\"bigdf.csv\")\n",
    "bigdf.reset_index(drop=True)\n",
    "bigdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_comments(commentsListAsString):\n",
    "    if type(commentsListAsString) != str:\n",
    "        return \"\"\n",
    "    else:\n",
    "        allComments = ast.literal_eval(commentsListAsString)\n",
    "        if len(allComments) >= MIN_PER_COURSESEM_REVIEWS:\n",
    "            return \" \".join(np.random.choice(allComments, MIN_PER_COURSESEM_REVIEWS, replace=False))\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "subdf = bigdf[['Course','C_Semester','Comments', 'Positive']].dropna()\n",
    "subdf[\"Sampled_Comments\"] = subdf.Comments.map(sample_comments)\n",
    "subdf = subdf[subdf.Sampled_Comments != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course</th>\n",
       "      <th>C_Semester</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Sampled_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '14</td>\n",
       "      <td>[u'The class has a fairly high work load, but ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The class has a fairly high work load, but Dr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '13</td>\n",
       "      <td>[u'Philosophy of the State with Dr. Chen offer...</td>\n",
       "      <td>False</td>\n",
       "      <td>Class discussions are often very interesting b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '12</td>\n",
       "      <td>[u'This was by far my favorite course. Dr. Che...</td>\n",
       "      <td>False</td>\n",
       "      <td>It is an enlightening class Dr. Chen is the ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '11</td>\n",
       "      <td>[u'Be prepared to read', u'Discussions were gr...</td>\n",
       "      <td>False</td>\n",
       "      <td>Dr. Owen Chen is an amazing, intellectually st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EXPOS-20.133</td>\n",
       "      <td>Spring '12</td>\n",
       "      <td>[u'This is a fantastic course if you have an i...</td>\n",
       "      <td>False</td>\n",
       "      <td>Very good class overall, but be prepared to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXPOS-20.133</td>\n",
       "      <td>Spring '14</td>\n",
       "      <td>[u'This is not a bad Expos course. Dr. Chen is...</td>\n",
       "      <td>False</td>\n",
       "      <td>The course is great if you put the effort into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '14</td>\n",
       "      <td>[u'If you are interested in political philosop...</td>\n",
       "      <td>False</td>\n",
       "      <td>I would recommend this class, the material is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '13</td>\n",
       "      <td>[u'This class involves quite a bit of reading,...</td>\n",
       "      <td>False</td>\n",
       "      <td>This is a difficult course, particularly for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '12</td>\n",
       "      <td>[u\"A basic, but thorough, understanding of phi...</td>\n",
       "      <td>False</td>\n",
       "      <td>In this class, you will get to work through a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '11</td>\n",
       "      <td>[u'It is a great class, which combines develop...</td>\n",
       "      <td>True</td>\n",
       "      <td>This class is difficult, and if you want a wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EXPOS-20.134</td>\n",
       "      <td>Spring '12</td>\n",
       "      <td>[u\"It won't always be easy, but this class def...</td>\n",
       "      <td>False</td>\n",
       "      <td>It won't always be easy, but this class defini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EXPOS-20.134</td>\n",
       "      <td>Spring '14</td>\n",
       "      <td>[u\"The reading material is interesting and cha...</td>\n",
       "      <td>True</td>\n",
       "      <td>While this is probably one of the hardest and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Course  C_Semester                                           Comments Positive                                   Sampled_Comments\n",
       "1   EXPOS-20.132    Fall '14  [u'The class has a fairly high work load, but ...    False  The class has a fairly high work load, but Dr....\n",
       "2   EXPOS-20.132    Fall '13  [u'Philosophy of the State with Dr. Chen offer...    False  Class discussions are often very interesting b...\n",
       "3   EXPOS-20.132    Fall '12  [u'This was by far my favorite course. Dr. Che...    False  It is an enlightening class Dr. Chen is the ma...\n",
       "4   EXPOS-20.132    Fall '11  [u'Be prepared to read', u'Discussions were gr...    False  Dr. Owen Chen is an amazing, intellectually st...\n",
       "6   EXPOS-20.133  Spring '12  [u'This is a fantastic course if you have an i...    False  Very good class overall, but be prepared to re...\n",
       "7   EXPOS-20.133  Spring '14  [u'This is not a bad Expos course. Dr. Chen is...    False  The course is great if you put the effort into...\n",
       "13  EXPOS-20.131    Fall '14  [u'If you are interested in political philosop...    False  I would recommend this class, the material is ...\n",
       "14  EXPOS-20.131    Fall '13  [u'This class involves quite a bit of reading,...    False  This is a difficult course, particularly for a...\n",
       "15  EXPOS-20.131    Fall '12  [u\"A basic, but thorough, understanding of phi...    False  In this class, you will get to work through a ...\n",
       "16  EXPOS-20.131    Fall '11  [u'It is a great class, which combines develop...     True  This class is difficult, and if you want a wal...\n",
       "19  EXPOS-20.134  Spring '12  [u\"It won't always be easy, but this class def...    False  It won't always be easy, but this class defini...\n",
       "20  EXPOS-20.134  Spring '14  [u\"The reading material is interesting and cha...     True  While this is probably one of the hardest and ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert our comments dataframe, subdf, to a spark dataframe for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/apache-spark/libexec\n"
     ]
    }
   ],
   "source": [
    "#setup spark\n",
    "import os\n",
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()\n",
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "import sys\n",
    "rdd = sc.parallelize(xrange(10),10)\n",
    "rdd.map(lambda x: sys.version).collect()\n",
    "sys.version\n",
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$^&*+-|=~_')\n",
    "from sklearn.feature_extraction import text \n",
    "stopwords=text.ENGLISH_STOP_WORDS\n",
    "import re\n",
    "regex1=re.compile(r\"\\.{2,}\")\n",
    "regex2=re.compile(r\"\\-{2,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a get parts function to parse the language in the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parts(thetext):\n",
    "    thetext=re.sub(regex1, ' ', thetext)\n",
    "    thetext=re.sub(regex2, ' ', thetext)\n",
    "    nouns=[]\n",
    "    descriptives=[]\n",
    "    for i,sentence in enumerate(parse(thetext, tokenize=True, lemmata=True).split()):\n",
    "        nouns.append([])\n",
    "        descriptives.append([])\n",
    "        for token in sentence:\n",
    "            #print token\n",
    "            if len(token[4]) >0:\n",
    "                if token[1] in ['JJ', 'JJR', 'JJS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    descriptives[i].append(token[4])\n",
    "                elif token[1] in ['NN', 'NNS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    nouns[i].append(token[4])\n",
    "    out=zip(nouns, descriptives)\n",
    "    nouns2=[]\n",
    "    descriptives2=[]\n",
    "    for n,d in out:\n",
    "        if len(n)!=0 and len(d)!=0:\n",
    "            nouns2.append(n)\n",
    "            descriptives2.append(d)\n",
    "    return nouns2, descriptives2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------------+--------+--------------------+\n",
      "|      Course|C_Semester|            Comments|Positive|    Sampled_Comments|\n",
      "+------------+----------+--------------------+--------+--------------------+\n",
      "|EXPOS-20.132|  Fall '14|[u'The class has ...|   false|The class has a f...|\n",
      "|EXPOS-20.132|  Fall '13|[u'Philosophy of ...|   false|Class discussions...|\n",
      "|EXPOS-20.132|  Fall '12|[u'This was by fa...|   false|It is an enlighte...|\n",
      "|EXPOS-20.132|  Fall '11|[u'Be prepared to...|   false|Dr. Owen Chen is ...|\n",
      "|EXPOS-20.133|Spring '12|[u'This is a fant...|   false|Very good class o...|\n",
      "+------------+----------+--------------------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subdf = sqlsc.createDataFrame(subdf)\n",
    "subdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[u'class', u'work', u'load', u'writer'],\n",
       "   [u'quality', u'instruction', u'course', u'instructor', u'time'],\n",
       "   [u'paper', u'family', u'state'],\n",
       "   [u'lot', u'grader'],\n",
       "   [u'teacher', u'though\\\\xe2\\\\u20ac\\\\u201dhe'],\n",
       "   [u'course'],\n",
       "   [u'subject', u'course', u'overall', u'expectation'],\n",
       "   [u'purpose',\n",
       "    u'class',\n",
       "    u'freshman',\n",
       "    u'writing',\n",
       "    u'skill',\n",
       "    u'class',\n",
       "    u'resource',\n",
       "    u'purpose'],\n",
       "   [u'work', u'effort', u'essay'],\n",
       "   [u'essay', u'topic', u'guidance'],\n",
       "   [u'feedback', u'draft', u'draft'],\n",
       "   [u'feedback', u'office', u'hour'],\n",
       "   [u'peer', u'resource', u'guidance', u'class'],\n",
       "   [u'class', u'requirement'],\n",
       "   [u'lot', u'work', u'summary', u'assignment']],\n",
       "  [[u\"u'the\", u'high', u'helpful'],\n",
       "   [u'generous'],\n",
       "   [u'final'],\n",
       "   [u'u\"a', u'hard'],\n",
       "   [u'good', u'smart', u'nice'],\n",
       "   [u'unlikely'],\n",
       "   [u'passionate'],\n",
       "   [u'useful'],\n",
       "   [u'manageable'],\n",
       "   [u'reasonable', u'little'],\n",
       "   [u'vague', u'unhelpful', u'final'],\n",
       "   [u'difficult', u'constructive', u'accessible'],\n",
       "   [u'writing'],\n",
       "   [u'particular'],\n",
       "   [u'prepared', u'dense', u'philosophical', u'online']])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_parts = subdf.rdd.map(lambda r: get_parts(r.Comments))\n",
    "comment_parts.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 519 ms, sys: 75.2 ms, total: 594 ms\n",
      "Wall time: 5min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parsedcomments=comment_parts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin our text analysis with an LDA of the nouns in the comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'class', u'work', u'load', u'writer'],\n",
       "  [u'quality', u'instruction', u'course', u'instructor', u'time'],\n",
       "  [u'paper', u'family', u'state'],\n",
       "  [u'lot', u'grader'],\n",
       "  [u'teacher', u'though\\\\xe2\\\\u20ac\\\\u201dhe'],\n",
       "  [u'course'],\n",
       "  [u'subject', u'course', u'overall', u'expectation'],\n",
       "  [u'purpose',\n",
       "   u'class',\n",
       "   u'freshman',\n",
       "   u'writing',\n",
       "   u'skill',\n",
       "   u'class',\n",
       "   u'resource',\n",
       "   u'purpose'],\n",
       "  [u'work', u'effort', u'essay'],\n",
       "  [u'essay', u'topic', u'guidance'],\n",
       "  [u'feedback', u'draft', u'draft'],\n",
       "  [u'feedback', u'office', u'hour'],\n",
       "  [u'peer', u'resource', u'guidance', u'class'],\n",
       "  [u'class', u'requirement'],\n",
       "  [u'lot', u'work', u'summary', u'assignment']],\n",
       " [[u\"u'philosophy\",\n",
       "   u'stimulating',\n",
       "   u'class',\n",
       "   u'discussion',\n",
       "   u'variety',\n",
       "   u'topic',\n",
       "   u'student',\n",
       "   u'share'],\n",
       "  [u'state', u'philosophy', u'course', u'class'],\n",
       "  [u'lot', u'philosophy', u'professor', u'lot'],\n",
       "  [u'course', u'lot', u'reading', u'writing'],\n",
       "  [u'philosophy',\n",
       "   u'state',\n",
       "   u'discussion',\n",
       "   u'struggle',\n",
       "   u'balance',\n",
       "   u'nature',\n",
       "   u'society',\n",
       "   u'course'],\n",
       "  [u\"u'i\",\n",
       "   u'deal',\n",
       "   u'philosophy',\n",
       "   u'writing',\n",
       "   u'focus',\n",
       "   u'philosophy',\n",
       "   u'writing',\n",
       "   u'writing',\n",
       "   u'class'],\n",
       "  [u\"u'philosophy\", u'state', u'class', u'writing', u'essay', u'college'],\n",
       "  [u'matter', u'society'],\n",
       "  [u'page',\n",
       "   u'reading',\n",
       "   u'day',\n",
       "   u'syllabus',\n",
       "   u'warning',\n",
       "   u'thing',\n",
       "   u'tardiness',\n",
       "   u'grade'],\n",
       "  [u'fact'],\n",
       "  [u'course'],\n",
       "  [u'reading', u'understanding', u'work'],\n",
       "  [u'course'],\n",
       "  [u\"u'i\", u'page', u'entirety', u'work'],\n",
       "  [u'class', u'material', u'experience'],\n",
       "  [u'class', u'lot'],\n",
       "  [u'class', u'improvement', u'writing', u'understanding', u'writing'],\n",
       "  [u'u\"class', u'discussion', u'class', u'lot', u'philosophy'],\n",
       "  [u\"u'most\", u'student', u'class', u'philosophy', u'level', u'discussion'],\n",
       "  [u'class', u'philosophy', u'introduction', u'course', u'ton', u'student']],\n",
       " [[u'course'],\n",
       "  [u'kind', u'class'],\n",
       "  [u'decision', u'course'],\n",
       "  [u'end', u'man'],\n",
       "  [u'reading', u'kid'],\n",
       "  [u'section', u'discussion', u'time', u'topic', u'student', u'point', u'way'],\n",
       "  [u'philosophy'],\n",
       "  [u'downside', u'writing', u'component'],\n",
       "  [u'writer', u'measure'],\n",
       "  [u'time', u'class', u'lot', u'class', u'discussion'],\n",
       "  [u'teacher'],\n",
       "  [u'reading', u'understanding', u'philosophy'],\n",
       "  [u'day', u'material'],\n",
       "  [u'philosophy',\n",
       "   u'kind',\n",
       "   u'style',\n",
       "   u'lot',\n",
       "   u'definition',\n",
       "   u'introduction',\n",
       "   u'writing',\n",
       "   u'topic',\n",
       "   u'concern',\n",
       "   u'philosophy'],\n",
       "  [u'list', u'course'],\n",
       "  [u'reading', u'bit', u'time', u'reading', u'discussion'],\n",
       "  [u'way', u'government', u'philosopher', u'time'],\n",
       "  [u\"u'it\", u'class', u\"u'take\", u'class', u'philosophy', u'politic'],\n",
       "  [u'reading', u'discussion'],\n",
       "  [u'writing'],\n",
       "  [u\"u'very\", u'subject', u'matter', u'discussion'],\n",
       "  [u'man', u'teacher']]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e[0] for e in parsedcomments[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'class', u'work', u'load', u'writer'],\n",
       " [u'quality', u'instruction', u'course', u'instructor', u'time'],\n",
       " [u'paper', u'family', u'state'],\n",
       " [u'lot', u'grader'],\n",
       " [u'teacher', u'though\\\\xe2\\\\u20ac\\\\u201dhe']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldadatardd=sc.parallelize([ele[0] for ele in parsedcomments]).flatMap(lambda l: l)\n",
    "ldadatardd.cache()\n",
    "ldadatardd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'class', u'work', u'load', u'writer', u'quality']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldadatardd.flatMap(lambda word: word).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabtups = (ldadatardd.flatMap(lambda word: word)\n",
    "             .map(lambda word: (word, 1))\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "             .map(lambda (x,y): x)\n",
    "             .zipWithIndex()\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=vocabtups.collectAsMap()\n",
    "id2word=vocabtups.map(lambda (x,y): (y,x)).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'u\"byrne', u'post-grad', 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0], vocab.keys()[5], vocab[vocab.keys()[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12291"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def helperfunction(element):\n",
    "    d = defaultdict(int)\n",
    "    for k in element:\n",
    "        d[vocab[k]] += 1\n",
    "    return d.items()\n",
    "documents = ldadatardd.map(lambda w: helperfunction(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(737, 1), (1890, 1), (1982, 1), (3145, 1)],\n",
       " [(4488, 1), (954, 1), (11246, 1), (4902, 1), (5503, 1)],\n",
       " [(1688, 1), (4602, 1), (10135, 1)],\n",
       " [(9696, 1), (4435, 1)],\n",
       " [(3835, 1), (5557, 1)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus=documents.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda2 = gensim.models.ldamodel.LdaModel(corpus = corpus, num_topics = 2, id2word=id2word, chunksize=200, passes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we print the topics we find using LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.189*class + 0.048*lot + 0.037*time + 0.029*work + 0.028*way + 0.027*professor + 0.026*problem + 0.023*section + 0.021*exam + 0.017*fun',\n",
       " u'0.122*course + 0.058*material + 0.049*lecture + 0.023*student + 0.018*topic + 0.017*reading + 0.017*person + 0.015*science + 0.013*year + 0.011*lecturer']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first topic (let us call this Topic 0) includes the combination of words: class, lot, time, work, way, professor, problem, section, exam, and fun.\n",
    "\n",
    "\n",
    "The second topic (let us call this Topic 1) includes course, material, lecture, student, topic, reading, person, science, year, and lecturer.\n",
    "\n",
    "\n",
    "Topic 0 seems to encompass the more interactive, qualitative, personable aspects of the course with key terms including student, professor, discussion, lecture, and fun. Topic 0, by contrast, seems to encompass the more solitary, logistical, factual aspects of the course with key terms including material, time, work, experience, paper, and field. One thing worth noticing is that Topic 0 includes \"course\" as a key term while Topic 1 includes \"class\". While \"course\" and \"class\" are often used interchangably in language, \"class\" arguably connotes a more personal, interactive experience than \"course\", which is more administrative and logistical and more likely to be used as an umbrella term for everything from everyday class to homework.\n",
    "\n",
    "\n",
    "In order to further evaluate our intial hypothesis that course reviews are split along two topics (interactive, qualitiative, personable aspects v. solitary, logistical aspects), we will output the words of some sentences, along with the probability of the sentence belonging to Topic 0 and Topic 1, to qualitatively check that our topics are reasonable and supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(737, 1), (1890, 1), (1982, 1), (3145, 1)]\n",
      "[(0, 0.70128553999146426), (1, 0.29871446000853574)]\n",
      "class writer load work\n",
      "==========================================\n",
      "[(3753, 1), (6562, 1)]\n",
      "[(0, 0.16667575000727794), (1, 0.83332424999272214)]\n",
      "concept background\n",
      "==========================================\n",
      "[(7218, 1)]\n",
      "[(0, 0.2500068679396345), (1, 0.74999313206036555)]\n",
      "reading\n",
      "==========================================\n",
      "[(4488, 1), (8096, 1), (2708, 1), (9767, 1)]\n",
      "[(0, 0.50239686130464922), (1, 0.49760313869535083)]\n",
      "time assignment philosophy night\n",
      "==========================================\n",
      "[(737, 1), (8153, 1), (1547, 1), (3145, 1)]\n",
      "[(0, 0.70025273369894947), (1, 0.29974726630105053)]\n",
      "class bit pass work\n",
      "==========================================\n",
      "[(4482, 1), (3908, 1), (9963, 1), (11729, 1), (8691, 1), (5977, 1)]\n",
      "[(0, 0.35332364587905613), (1, 0.64667635412094382)]\n",
      "thought-provoking discussion debate material staff teaching\n",
      "==========================================\n",
      "[(954, 1), (4435, 1)]\n",
      "[(0, 0.49999399699406566), (1, 0.50000600300593423)]\n",
      "course lot\n",
      "==========================================\n",
      "[(4488, 1), (8153, 1), (954, 1), (939, 1)]\n",
      "[(0, 0.37111633670593241), (1, 0.62888366329406753)]\n",
      "time bit course u\"must\n",
      "==========================================\n",
      "[(737, 1), (3811, 1), (4424, 1), (650, 1), (4364, 1), (8744, 1), (4435, 1), (4735, 1)]\n",
      "[(0, 0.69536191499620525), (1, 0.30463808500379475)]\n",
      "class cost intervention u'very benefit reform lot issue\n",
      "==========================================\n",
      "[(737, 1), (12066, 1), (8931, 1), (1750, 1), (10550, 1), (9111, 1), (954, 1), (11419, 1), (11966, 1)]\n",
      "[(0, 0.6501795247027311), (1, 0.34982047529726884)]\n",
      "class student success belief stand risk course question ability\n",
      "==========================================\n",
      "[(3008, 1), (5921, 1), (954, 1), (4435, 1), (4193, 1)]\n",
      "[(0, 0.4142126190592062), (1, 0.58578738094079374)]\n",
      "chance education course lot style\n",
      "==========================================\n",
      "[(12066, 1), (4746, 1)]\n",
      "[(0, 0.49900389563705511), (1, 0.50099610436294484)]\n",
      "student reason\n",
      "==========================================\n",
      "[(5668, 1), (954, 1), (3804, 1)]\n",
      "[(0, 0.125210772737264), (1, 0.874789227262736)]\n",
      "career course regret\n",
      "==========================================\n",
      "[(5921, 1), (7610, 1), (4435, 1), (9963, 1), (4633, 1)]\n",
      "[(0, 0.25008569737102754), (1, 0.74991430262897241)]\n",
      "education perspective lot debate history\n",
      "==========================================\n",
      "[(737, 1), (11042, 1)]\n",
      "[(0, 0.83294305187589424), (1, 0.16705694812410585)]\n",
      "class kink\n",
      "==========================================\n",
      "[(3680, 1), (377, 1), (737, 1), (3908, 1), (11729, 1)]\n",
      "[(0, 0.75000741668003779), (1, 0.24999258331996213)]\n",
      "way professor class discussion material\n",
      "==========================================\n",
      "[(3680, 1), (737, 1), (4213, 1), (3094, 1)]\n",
      "[(0, 0.50018155051153279), (1, 0.49981844948846721)]\n",
      "way class overview study\n",
      "==========================================\n",
      "[(4280, 1), (377, 1), (348, 1), (737, 1)]\n",
      "[(0, 0.69996330497571002), (1, 0.30003669502428998)]\n",
      "food professor person class\n",
      "==========================================\n",
      "[(737, 1), (1554, 1), (3908, 1), (12066, 1)]\n",
      "[(0, 0.70001567671863363), (1, 0.29998432328136626)]\n",
      "class section discussion student\n",
      "==========================================\n",
      "[(4488, 1), (11256, 1), (1730, 1)]\n",
      "[(0, 0.87499603811284432), (1, 0.12500396188715568)]\n",
      "time homework week\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "for bow in corpus[0:1200:60]:\n",
    "    print bow\n",
    "    print lda2.get_document_topics(bow)\n",
    "    print \" \".join([id2word[e[0]] for e in bow])\n",
    "    print \"==========================================\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"sentences\" (or bag-of-words) which have a much greater probability of belonging to Topic 0 include:\n",
    "- field class thesis work\n",
    "- bit work lab\n",
    "- order course thing\n",
    "\n",
    "\n",
    "The words in these sentences relate to more impersonal, logistical aspects of a course. Specifically, \"field\", \"thesis\", \"work\", and \"order\" describe inflexible, solitary, requirement aspects of a course while \"bit\" and \"thing\" are more vague but nevertheless imply a degree of impartiability and detatchedness.\n",
    "\n",
    "\n",
    "\n",
    "The \"setences\" which have a much greater probability of belonging to Topic 1 include:\n",
    "- depth course grad class history student question\n",
    "- concept commitment moment life\n",
    "- section lecture exam reading drawback concept\n",
    "- class entertaining\n",
    "- evolution class pre cinema\n",
    "\n",
    "Words in these sentences that are not present in the previous cluster of setences and that stand out as implying more creative, interactive, person-to-person aspects of a course include \"depth\", \"history\", \"question\", \"concept\", \"commitment\", \"moment\", \"life\", \"drawback\", \"lecture\", and \"entertaining\". \n",
    "\n",
    "The \"sentences\" which have more equal probabilities of belonging to Topic 0 or 1 include:\n",
    "- lecture person\n",
    "- resource professor man kind topic\n",
    "\n",
    "We can observe words implying more logistical aspects (\"resource\", \"topic\") and more interactive, creative aspects (\"professor\", \"kind\"). \n",
    "\n",
    "\n",
    "Of course, words such as \"lecture\" can belong to either topic since lecture is both a logistical, required part of most courses and an engaging, potentially interactive opportunity for students to learn from professors. From our analysis of the topic probabilities and bag-of-words above, however, there appears to be evidence to support our initial hypothesis that course reviews are split along two topics: Topic 0, which includes more solitary, logistical aspects and Topic 1, which includes more interactive, qualitative, personable aspects of a course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DOs:\n",
    "- We can consider doing \"verbs\" (use TextBlob)\n",
    "- Detect \"not\" before adjectives, this shouldn't be too difficult\n",
    "- Text before pushing\n",
    "- Look at differences across departments (Jesse/Andrew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
