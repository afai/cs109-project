{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curious Comments \n",
    "![commentpic](comment_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A critical part of any review are the comments. We will now proceed to analyze the comments in our q data. We will judge the predictive power of these comments, and analyze the role they play in a score's q rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import os\n",
    "import math\n",
    "from itertools import chain\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by creating a dataframe of comments. We will randomly subsample 10 comments per review and only consider courses 10 or more comments. Our dataframe will consist of three columns; Comment, Course and Overall Positive Rating. A course defined to have an 'Overall Positive Rating' if it has been been given more positive ratings than negative ratings across all semesters that it has been rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_PER_COURSE_SAMPLES = 10\n",
    "#print tempdf[tempdf['C_Number'] == 'SOC-STD 98nw'].Comments.tolist()[0]\n",
    "#tempdf.groupby('C_Number').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigdf=pd.read_csv(\"bigdf.csv\")\n",
    "bigdf.reset_index(drop=True)\n",
    "tempdf = bigdf[['Course','Comments', 'Positive']].dropna()\n",
    "subdf = pd.DataFrame()\n",
    "for course in tempdf.groupby('Course').groups:\n",
    "    allCourseComments = []\n",
    "    allSemesterComments = tempdf[tempdf.Course == course].Comments.tolist()\n",
    "    allSemesterPositives = tempdf[tempdf.Course == course].Positive.tolist()\n",
    "    for eachSemesterComments in allSemesterComments:\n",
    "        allCourseComments = allCourseComments + ast.literal_eval(eachSemesterComments)\n",
    "    if len(allCourseComments) >= 10:\n",
    "        sample = np.random.choice(allCourseComments, MAX_PER_COURSE_SAMPLES, replace=False)\n",
    "        coursedf = pd.DataFrame()\n",
    "        coursedf['Comment'] = sample\n",
    "        coursedf['Course'] = course\n",
    "        #citation: http://stackoverflow.com/questions/1518522/python-most-common-element-in-a-list\n",
    "        coursedf['Overall Positive Rating'] = max(set(allSemesterPositives), key=allSemesterPositives.count)\n",
    "        subdf = pd.concat([subdf,coursedf]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Course</th>\n",
       "      <th>Overall Positive Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The opportunity to have a one-on-one tutorial ...</td>\n",
       "      <td>RELIGION-98a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an invaluable opportunity, make it yours.</td>\n",
       "      <td>RELIGION-98a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do your reading, go to class prepared, and you...</td>\n",
       "      <td>RELIGION-98a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent readings, great leader, really enjoy...</td>\n",
       "      <td>RELIGION-98a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's a thorough, informative way to delve into...</td>\n",
       "      <td>RELIGION-98a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Well, all religion concentrators need to take ...</td>\n",
       "      <td>RELIGION-98a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Be prepared to let your intellectual horizons ...</td>\n",
       "      <td>RELIGION-98a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Though it was created for me, I think this syl...</td>\n",
       "      <td>RELIGION-98a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can learn a lot studying under Chip's tutelage.</td>\n",
       "      <td>RELIGION-98a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you get a small tutorial like I did, be pre...</td>\n",
       "      <td>RELIGION-98a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>This course gets harder towards the end. The l...</td>\n",
       "      <td>COMPSCI-187</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>If you're interested in computational linguist...</td>\n",
       "      <td>COMPSCI-187</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The workload is lightweight conceptually, but ...</td>\n",
       "      <td>COMPSCI-187</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>It's a useful way to advance understanding of ...</td>\n",
       "      <td>COMPSCI-187</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment        Course Overall Positive Rating\n",
       "0   The opportunity to have a one-on-one tutorial ...  RELIGION-98a                    True\n",
       "1   This is an invaluable opportunity, make it yours.  RELIGION-98a                    True\n",
       "2   Do your reading, go to class prepared, and you...  RELIGION-98a                    True\n",
       "3   Excellent readings, great leader, really enjoy...  RELIGION-98a                    True\n",
       "4   It's a thorough, informative way to delve into...  RELIGION-98a                    True\n",
       "5   Well, all religion concentrators need to take ...  RELIGION-98a                    True\n",
       "6   Be prepared to let your intellectual horizons ...  RELIGION-98a                    True\n",
       "7   Though it was created for me, I think this syl...  RELIGION-98a                    True\n",
       "8     Can learn a lot studying under Chip's tutelage.  RELIGION-98a                    True\n",
       "9   If you get a small tutorial like I did, be pre...  RELIGION-98a                    True\n",
       "10  This course gets harder towards the end. The l...   COMPSCI-187                   False\n",
       "11  If you're interested in computational linguist...   COMPSCI-187                   False\n",
       "12  The workload is lightweight conceptually, but ...   COMPSCI-187                   False\n",
       "13  It's a useful way to advance understanding of ...   COMPSCI-187                   False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert our comments dataframe, subdf, to a spark dataframe for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vagrant/spark\n"
     ]
    }
   ],
   "source": [
    "#setup spark\n",
    "import os\n",
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()\n",
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"5g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "import sys\n",
    "rdd = sc.parallelize(xrange(10),10)\n",
    "rdd.map(lambda x: sys.version).collect()\n",
    "sys.version\n",
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$^&*+-|=~_')\n",
    "from sklearn.feature_extraction import text \n",
    "stopwords=text.ENGLISH_STOP_WORDS\n",
    "import re\n",
    "regex1=re.compile(r\"\\.{2,}\")\n",
    "regex2=re.compile(r\"\\-{2,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a get parts function to parse the language in the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parts(thetext):\n",
    "    thetext=re.sub(regex1, ' ', thetext)\n",
    "    thetext=re.sub(regex2, ' ', thetext)\n",
    "    nouns=[]\n",
    "    descriptives=[]\n",
    "    for i,sentence in enumerate(parse(thetext, tokenize=True, lemmata=True).split()):\n",
    "        nouns.append([])\n",
    "        descriptives.append([])\n",
    "        for token in sentence:\n",
    "            #print token\n",
    "            if len(token[4]) >0:\n",
    "                if token[1] in ['JJ', 'JJR', 'JJS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    descriptives[i].append(token[4])\n",
    "                elif token[1] in ['NN', 'NNS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    nouns[i].append(token[4])\n",
    "    out=zip(nouns, descriptives)\n",
    "    nouns2=[]\n",
    "    descriptives2=[]\n",
    "    for n,d in out:\n",
    "        if len(n)!=0 and len(d)!=0:\n",
    "            nouns2.append(n)\n",
    "            descriptives2.append(d)\n",
    "    return nouns2, descriptives2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------------------+\n",
      "|             Comment|      Course|Overall Positive Rating|\n",
      "+--------------------+------------+-----------------------+\n",
      "|The opportunity t...|RELIGION-98a|                   true|\n",
      "|This is an invalu...|RELIGION-98a|                   true|\n",
      "|Do your reading, ...|RELIGION-98a|                   true|\n",
      "|Excellent reading...|RELIGION-98a|                   true|\n",
      "|It's a thorough, ...|RELIGION-98a|                   true|\n",
      "+--------------------+------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subdf = sqlsc.createDataFrame(subdf)\n",
    "subdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[u'opportunity', u'tutorial', u'individual']],\n",
       "  [[u'one-on-one', u'incredible']]),\n",
       " ([[u'opportunity']], [[u'invaluable']]),\n",
       " ([], []),\n",
       " ([[u'reading', u'leader', u'reading', u'material']],\n",
       "  [[u'excellent', u'great', u'enjoyed']]),\n",
       " ([[u'way', u'dialogue', u'religion', u'science', u'regard', u'evolution']],\n",
       "  [[u'thorough', u'informative']])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_parts = subdf.rdd.map(lambda r: get_parts(r.Comment))\n",
    "comment_parts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 21.1 ms, total: 179 ms\n",
      "Wall time: 55.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parsedcomments=comment_parts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin our text analysis with an LDA of the nouns in the comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'opportunity', u'tutorial', u'individual']], [[u'opportunity']], []]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e[0] for e in parsedcomments[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'opportunity', u'tutorial', u'individual'],\n",
       " [u'opportunity'],\n",
       " [u'reading', u'leader', u'reading', u'material'],\n",
       " [u'way', u'dialogue', u'religion', u'science', u'regard', u'evolution'],\n",
       " [u'non-concentrator', u'class', u'religion']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldadatardd=sc.parallelize([ele[0] for ele in parsedcomments]).flatMap(lambda l: l)\n",
    "ldadatardd.cache()\n",
    "ldadatardd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'opportunity', u'tutorial', u'individual', u'opportunity', u'reading']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldadatardd.flatMap(lambda word: word).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabtups = (ldadatardd.flatMap(lambda word: word)\n",
    "             .map(lambda word: (word, 1))\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "             .map(lambda (x,y): x)\n",
    "             .zipWithIndex()\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=vocabtups.collectAsMap()\n",
    "id2word=vocabtups.map(lambda (x,y): (y,x)).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'req', u'dynasty', 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0], vocab.keys()[5], vocab[vocab.keys()[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3898"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def helperfunction(element):\n",
    "    d = defaultdict(int)\n",
    "    for k in element:\n",
    "        d[vocab[k]] += 1\n",
    "    return d.items()\n",
    "documents = ldadatardd.map(lambda w: helperfunction(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2464, 1), (682, 1), (781, 1)],\n",
       " [(682, 1)],\n",
       " [(2003, 1), (3742, 1), (1526, 2)],\n",
       " [(2085, 1), (1233, 1), (3850, 1), (1841, 1), (981, 1), (858, 1)],\n",
       " [(3360, 1), (981, 1), (3423, 1)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus=documents.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda2 = gensim.models.ldamodel.LdaModel(corpus = corpus, num_topics = 2, id2word=id2word, chunksize=200, passes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we print the topics we find using LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.129*course + 0.046*material + 0.026*lecture + 0.025*topic + 0.023*professor + 0.015*way + 0.014*history + 0.013*year + 0.012*problem + 0.011*question'),\n",
       " (1,\n",
       "  u'0.179*class + 0.043*lot + 0.031*student + 0.029*time + 0.025*work + 0.022*reading + 0.017*discussion + 0.016*paper + 0.015*fun + 0.014*research')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first topic (let us call this Topic 0) includes the combination of words: course, lot, material, time, way, work, experience, paper, field, and person. \n",
    "\n",
    "\n",
    "The second topic (let us call this Topic 1) includes the combination of words: class, course, student, professor, lecture, reading, history, topic, discussion, and fun.\n",
    "\n",
    "\n",
    "Topic 1 seems to encompass the more interactive, qualitative, personable aspects of the course with key terms including student, professor, discussion, lecture, and fun. Topic 0, by contrast, seems to encompass the more solitary, logistical, factual aspects of the course with key terms including material, time, work, experience, paper, and field. One thing worth noticing is that both topics include \"course\" as a key term but only Topic 1 includes \"class\". While \"course\" and \"class\" are often used interchangably in language, \"class\" arguably connotes a more personal, interactive experience than \"course\", which is more administrative and logistical and more likely to be used as an umbrella term for everything from everyday class to homework.\n",
    "\n",
    "\n",
    "In order to further evaluate our intial hypothesis that course reviews are split along two topics (interactive, qualitiative, personable aspects v. solitary, logistical aspects), we will output the words of some sentences, along with the probability of the sentence belonging to Topic 0 and Topic 1, to qualitatively check that our topics are reasonable and supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2464, 1), (682, 1), (781, 1)]\n",
      "[(0, 0.37402945436085688), (1, 0.62597054563914312)]\n",
      "individual opportunity tutorial\n",
      "==========================================\n",
      "[(929, 2), (2628, 1), (390, 2), (3718, 1), (2369, 1), (2775, 1), (3228, 1)]\n",
      "[(0, 0.70656544083864192), (1, 0.29343455916135819)]\n",
      "diet edge nutrition recommendation finding guideline math\n",
      "==========================================\n",
      "[(3225, 1), (1563, 1), (2575, 1)]\n",
      "[(0, 0.62695519457571203), (1, 0.37304480542428808)]\n",
      "lecture learning homework\n",
      "==========================================\n",
      "[(2563, 1)]\n",
      "[(0, 0.74986962180603833), (1, 0.25013037819396161)]\n",
      "instructor\n",
      "==========================================\n",
      "[(2297, 1), (514, 1), (459, 1), (1885, 1)]\n",
      "[(0, 0.8911380396522296), (1, 0.1088619603477704)]\n",
      "introduction linguist syntax field\n",
      "==========================================\n",
      "[(1368, 1), (3433, 1), (1475, 1), (2741, 1)]\n",
      "[(0, 0.32013442627167082), (1, 0.67986557372832912)]\n",
      "orgo undergrad enthusiasm step\n",
      "==========================================\n",
      "[(3360, 1), (2578, 1)]\n",
      "[(0, 0.16667798047327986), (1, 0.83332201952672014)]\n",
      "class fun\n",
      "==========================================\n",
      "[(2297, 1), (2851, 1), (1309, 1)]\n",
      "[(0, 0.62510619781304499), (1, 0.37489380218695495)]\n",
      "introduction department language\n",
      "==========================================\n",
      "[(403, 1)]\n",
      "[(0, 0.25015581326860203), (1, 0.74984418673139797)]\n",
      "seminar\n",
      "==========================================\n",
      "[(1448, 1), (3225, 1), (2685, 1), (2047, 1)]\n",
      "[(0, 0.65998378227465337), (1, 0.34001621772534663)]\n",
      "rambling lecture bit semester\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "for bow in corpus[0:1000:100]:\n",
    "    print bow\n",
    "    print lda2.get_document_topics(bow)\n",
    "    print \" \".join([id2word[e[0]] for e in bow])\n",
    "    print \"==========================================\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"sentences\" (or bag-of-words) which have a much greater probability of belonging to Topic 0 include:\n",
    "- field class thesis work\n",
    "- bit work lab\n",
    "- order course thing\n",
    "\n",
    "\n",
    "The words in these sentences relate to more impersonal, logistical aspects of a course. Specifically, \"field\", \"thesis\", \"work\", and \"order\" describe inflexible, solitary, requirement aspects of a course while \"bit\" and \"thing\" are more vague but nevertheless imply a degree of impartiability and detatchedness.\n",
    "\n",
    "\n",
    "\n",
    "The \"setences\" which have a much greater probability of belonging to Topic 1 include:\n",
    "- depth course grad class history student question\n",
    "- concept commitment moment life\n",
    "- section lecture exam reading drawback concept\n",
    "- class entertaining\n",
    "- evolution class pre cinema\n",
    "\n",
    "Words in these sentences that are not present in the previous cluster of setences and that stand out as implying more creative, interactive, person-to-person aspects of a course include \"depth\", \"history\", \"question\", \"concept\", \"commitment\", \"moment\", \"life\", \"drawback\", \"lecture\", and \"entertaining\". \n",
    "\n",
    "The \"sentences\" which have more equal probabilities of belonging to Topic 0 or 1 include:\n",
    "- lecture person\n",
    "- resource professor man kind topic\n",
    "\n",
    "We can observe words implying more logistical aspects (\"resource\", \"topic\") and more interactive, creative aspects (\"professor\", \"kind\"). \n",
    "\n",
    "\n",
    "Of course, words such as \"lecture\" can belong to either topic since lecture is both a logistical, required part of most courses and an engaging, potentially interactive opportunity for students to learn from professors. From our analysis of the topic probabilities and bag-of-words above, however, there appears to be evidence to support our initial hypothesis that course reviews are split along two topics: Topic 0, which includes more solitary, logistical aspects and Topic 1, which includes more interactive, qualitative, personable aspects of a course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DOs:\n",
    "- We can consider doing \"verbs\" (use TextBlob)\n",
    "- Detect \"not\" before adjectives, this shouldn't be too difficult\n",
    "- Text before pushing\n",
    "- Look at differences across departments (Jesse/Andrew)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
