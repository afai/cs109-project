{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curious Comments \n",
    "![commentpic](comment_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A critical part of any review are the comments. We will now proceed to analyze the comments in our q data. We will judge the predictive power of these comments, and analyze the role they play in a score's q rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import os\n",
    "import math\n",
    "from itertools import chain\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by creating a dataframe of comments. We will randomly subsample 10 comments per review and only consider courses 10 or more comments. Our dataframe will consist of three columns; Comment, Course and Overall Positive Rating. A course defined to have an 'Overall Positive Rating' if it has been been given more positive ratings than negative ratings across all semesters that it has been rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIN_PER_COURSESEM_REVIEWS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_Department</th>\n",
       "      <th>C_Number</th>\n",
       "      <th>Course</th>\n",
       "      <th>C_CatNum</th>\n",
       "      <th>C_ID</th>\n",
       "      <th>C_Semester</th>\n",
       "      <th>C_Year</th>\n",
       "      <th>C_Term</th>\n",
       "      <th>C_Overall</th>\n",
       "      <th>C_Workload</th>\n",
       "      <th>C_Difficulty</th>\n",
       "      <th>C_Recommendation</th>\n",
       "      <th>C_Enrollment</th>\n",
       "      <th>C_ResponseRate</th>\n",
       "      <th>I_First</th>\n",
       "      <th>I_Last</th>\n",
       "      <th>I_ID</th>\n",
       "      <th>I_Overall</th>\n",
       "      <th>I_EffectiveLectures</th>\n",
       "      <th>I_Accessible</th>\n",
       "      <th>I_GeneratesEnthusiasm</th>\n",
       "      <th>I_EncouragesParticipation</th>\n",
       "      <th>I_UsefulFeedback</th>\n",
       "      <th>I_ReturnsAssignmentsTimely</th>\n",
       "      <th>QOverall_1</th>\n",
       "      <th>QOverall_2</th>\n",
       "      <th>QOverall_3</th>\n",
       "      <th>QOverall_4</th>\n",
       "      <th>QOverall_5</th>\n",
       "      <th>QDifficulty_1</th>\n",
       "      <th>QDifficulty_2</th>\n",
       "      <th>QDifficulty_3</th>\n",
       "      <th>QDifficulty_4</th>\n",
       "      <th>QDifficulty_5</th>\n",
       "      <th>QWorkload_1</th>\n",
       "      <th>QWorkload_2</th>\n",
       "      <th>QWorkload_3</th>\n",
       "      <th>QWorkload_4</th>\n",
       "      <th>QWorkload_5</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sem_Average</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTSCI</td>\n",
       "      <td>270</td>\n",
       "      <td>HISTSCI-270</td>\n",
       "      <td>58523</td>\n",
       "      <td>2697</td>\n",
       "      <td>Spring '12</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6</td>\n",
       "      <td>50.00</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Lemov</td>\n",
       "      <td>79de794d3e2e19eb71a2033b0ec0b76d</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'This course is a perfect example of what gr...</td>\n",
       "      <td>4.226350</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '14</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4.10</td>\n",
       "      <td>7.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50</td>\n",
       "      <td>13</td>\n",
       "      <td>76.92</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'The class has a fairly high work load, but ...</td>\n",
       "      <td>4.244370</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '13</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.20</td>\n",
       "      <td>13</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'Philosophy of the State with Dr. Chen offer...</td>\n",
       "      <td>4.256888</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '12</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>3.73</td>\n",
       "      <td>2.47</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.47</td>\n",
       "      <td>15</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.64</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'This was by far my favorite course. Dr. Che...</td>\n",
       "      <td>4.190299</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '11</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.62</td>\n",
       "      <td>13</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'Be prepared to read', u'Discussions were gr...</td>\n",
       "      <td>4.185893</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  C_Department C_Number        Course  C_CatNum  C_ID  C_Semester  C_Year  C_Term  C_Overall  C_Workload  C_Difficulty  C_Recommendation  C_Enrollment  C_ResponseRate  I_First I_Last                              I_ID  I_Overall  I_EffectiveLectures  I_Accessible  I_GeneratesEnthusiasm  I_EncouragesParticipation  I_UsefulFeedback  I_ReturnsAssignmentsTimely  QOverall_1  QOverall_2  QOverall_3  QOverall_4  QOverall_5  QDifficulty_1  QDifficulty_2  QDifficulty_3  QDifficulty_4  QDifficulty_5  \\\n",
       "0      HISTSCI      270   HISTSCI-270     58523  2697  Spring '12    2011       2       4.67        2.33          3.33              5.00             6           50.00  Rebecca  Lemov  79de794d3e2e19eb71a2033b0ec0b76d       4.67                 4.33          4.00                   4.33                       5.00              4.50                        4.00           0           0           0           1           2              0              0              2              1              0   \n",
       "1        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '14    2014       1       4.10        7.10           NaN              3.50            13           76.92     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       4.50                 4.60          3.70                   3.90                       3.90              4.10                        4.60           0           1           1           4           4              0              1              2              7              3   \n",
       "2        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '13    2013       1       3.50        2.60          3.90              3.20            13          100.00     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       3.80                 4.00          2.50                   3.50                       4.10              4.30                        4.40           0           1           1           4           4              0              1              2              7              3   \n",
       "3        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '12    2012       1       3.73        2.47          3.67              3.47            15          100.00     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       3.87                 4.33          2.64                   3.93                       4.18              3.64                        3.82           0           1           1           4           4              0              1              2              7              3   \n",
       "4        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '11    2011       1       3.85        2.00          3.54              3.62            13          100.00     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       4.08                 3.75          3.31                   3.92                       4.46              4.23                        4.08           0           1           1           4           4              0              1              2              7              3   \n",
       "\n",
       "   QWorkload_1  QWorkload_2  QWorkload_3  QWorkload_4  QWorkload_5                                           Comments  Sem_Average Positive  \n",
       "0            0            2            1            0            0  [u'This course is a perfect example of what gr...     4.226350     True  \n",
       "1            1            3            4            1            0  [u'The class has a fairly high work load, but ...     4.244370    False  \n",
       "2            1            3            4            1            0  [u'Philosophy of the State with Dr. Chen offer...     4.256888    False  \n",
       "3            1            3            4            1            0  [u'This was by far my favorite course. Dr. Che...     4.190299    False  \n",
       "4            1            3            4            1            0  [u'Be prepared to read', u'Discussions were gr...     4.185893    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdf=pd.read_csv(\"bigdf.csv\")\n",
    "bigdf.reset_index(drop=True)\n",
    "bigdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_comments(commentsListAsString):\n",
    "    if type(commentsListAsString) != str:\n",
    "        return \"\"\n",
    "    else:\n",
    "        allComments = ast.literal_eval(commentsListAsString)\n",
    "        if len(allComments) >= MIN_PER_COURSESEM_REVIEWS:\n",
    "            return \" \".join(np.random.choice(allComments, MIN_PER_COURSESEM_REVIEWS, replace=False))\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "subdf = bigdf[['Course','C_Semester','Comments', 'Positive']].dropna()\n",
    "subdf[\"Sampled_Comments\"] = subdf.Comments.map(sample_comments)\n",
    "subdf = subdf[subdf.Sampled_Comments != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course</th>\n",
       "      <th>C_Semester</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Sampled_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '14</td>\n",
       "      <td>[u'The class has a fairly high work load, but ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NAH A lot of reading and he's a hard grader. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '13</td>\n",
       "      <td>[u'Philosophy of the State with Dr. Chen offer...</td>\n",
       "      <td>False</td>\n",
       "      <td>Philosophy of the state is a very difficult cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '12</td>\n",
       "      <td>[u'This was by far my favorite course. Dr. Che...</td>\n",
       "      <td>False</td>\n",
       "      <td>Take this class if you are interested in the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '11</td>\n",
       "      <td>[u'Be prepared to read', u'Discussions were gr...</td>\n",
       "      <td>False</td>\n",
       "      <td>This was my favorite class from freshman fall,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EXPOS-20.133</td>\n",
       "      <td>Spring '12</td>\n",
       "      <td>[u'This is a fantastic course if you have an i...</td>\n",
       "      <td>False</td>\n",
       "      <td>The class discussions are excellent, a lot of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXPOS-20.133</td>\n",
       "      <td>Spring '14</td>\n",
       "      <td>[u'This is not a bad Expos course. Dr. Chen is...</td>\n",
       "      <td>False</td>\n",
       "      <td>The course is great if you put the effort into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '14</td>\n",
       "      <td>[u'If you are interested in political philosop...</td>\n",
       "      <td>False</td>\n",
       "      <td>This course is definitely the hardest of the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '13</td>\n",
       "      <td>[u'This class involves quite a bit of reading,...</td>\n",
       "      <td>False</td>\n",
       "      <td>This course may seem intimidating at first but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '12</td>\n",
       "      <td>[u\"A basic, but thorough, understanding of phi...</td>\n",
       "      <td>False</td>\n",
       "      <td>Expect to put in more time per week for this E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '11</td>\n",
       "      <td>[u'It is a great class, which combines develop...</td>\n",
       "      <td>True</td>\n",
       "      <td>Be prepared to devote a substantial amount of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EXPOS-20.134</td>\n",
       "      <td>Spring '12</td>\n",
       "      <td>[u\"It won't always be easy, but this class def...</td>\n",
       "      <td>False</td>\n",
       "      <td>A lot of reading, very specific paper topics, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EXPOS-20.134</td>\n",
       "      <td>Spring '14</td>\n",
       "      <td>[u\"The reading material is interesting and cha...</td>\n",
       "      <td>True</td>\n",
       "      <td>The reading material is interesting and challe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Course  C_Semester                                           Comments Positive                                   Sampled_Comments\n",
       "1   EXPOS-20.132    Fall '14  [u'The class has a fairly high work load, but ...    False  NAH A lot of reading and he's a hard grader. A...\n",
       "2   EXPOS-20.132    Fall '13  [u'Philosophy of the State with Dr. Chen offer...    False  Philosophy of the state is a very difficult cl...\n",
       "3   EXPOS-20.132    Fall '12  [u'This was by far my favorite course. Dr. Che...    False  Take this class if you are interested in the c...\n",
       "4   EXPOS-20.132    Fall '11  [u'Be prepared to read', u'Discussions were gr...    False  This was my favorite class from freshman fall,...\n",
       "6   EXPOS-20.133  Spring '12  [u'This is a fantastic course if you have an i...    False  The class discussions are excellent, a lot of ...\n",
       "7   EXPOS-20.133  Spring '14  [u'This is not a bad Expos course. Dr. Chen is...    False  The course is great if you put the effort into...\n",
       "13  EXPOS-20.131    Fall '14  [u'If you are interested in political philosop...    False  This course is definitely the hardest of the e...\n",
       "14  EXPOS-20.131    Fall '13  [u'This class involves quite a bit of reading,...    False  This course may seem intimidating at first but...\n",
       "15  EXPOS-20.131    Fall '12  [u\"A basic, but thorough, understanding of phi...    False  Expect to put in more time per week for this E...\n",
       "16  EXPOS-20.131    Fall '11  [u'It is a great class, which combines develop...     True  Be prepared to devote a substantial amount of ...\n",
       "19  EXPOS-20.134  Spring '12  [u\"It won't always be easy, but this class def...    False  A lot of reading, very specific paper topics, ...\n",
       "20  EXPOS-20.134  Spring '14  [u\"The reading material is interesting and cha...     True  The reading material is interesting and challe..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert our comments dataframe, subdf, to a spark dataframe for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vagrant/spark\n"
     ]
    }
   ],
   "source": [
    "#setup spark\n",
    "import os\n",
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()\n",
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "import sys\n",
    "rdd = sc.parallelize(xrange(10),10)\n",
    "rdd.map(lambda x: sys.version).collect()\n",
    "sys.version\n",
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$^&*+-|=~_')\n",
    "from sklearn.feature_extraction import text \n",
    "stopwords=text.ENGLISH_STOP_WORDS\n",
    "import re\n",
    "regex1=re.compile(r\"\\.{2,}\")\n",
    "regex2=re.compile(r\"\\-{2,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a get parts function to parse the language in the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parts(thetext):\n",
    "    thetext=re.sub(regex1, ' ', thetext)\n",
    "    thetext=re.sub(regex2, ' ', thetext)\n",
    "    nouns=[]\n",
    "    descriptives=[]\n",
    "    for i,sentence in enumerate(parse(thetext, tokenize=True, lemmata=True).split()):\n",
    "        nouns.append([])\n",
    "        descriptives.append([])\n",
    "        for token in sentence:\n",
    "            #print token\n",
    "            if len(token[4]) >0:\n",
    "                if token[1] in ['JJ', 'JJR', 'JJS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    descriptives[i].append(token[4])\n",
    "                elif token[1] in ['NN', 'NNS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    nouns[i].append(token[4])\n",
    "    out=zip(nouns, descriptives)\n",
    "    nouns2=[]\n",
    "    descriptives2=[]\n",
    "    for n,d in out:\n",
    "        if len(n)!=0 and len(d)!=0:\n",
    "            nouns2.append(n)\n",
    "            descriptives2.append(d)\n",
    "    return nouns2, descriptives2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------------+--------+--------------------+\n",
      "|      Course|C_Semester|            Comments|Positive|    Sampled_Comments|\n",
      "+------------+----------+--------------------+--------+--------------------+\n",
      "|EXPOS-20.132|  Fall '14|[u'The class has ...|   false|NAH A lot of read...|\n",
      "|EXPOS-20.132|  Fall '13|[u'Philosophy of ...|   false|Philosophy of the...|\n",
      "|EXPOS-20.132|  Fall '12|[u'This was by fa...|   false|Take this class i...|\n",
      "|EXPOS-20.132|  Fall '11|[u'Be prepared to...|   false|This was my favor...|\n",
      "|EXPOS-20.133|Spring '12|[u'This is a fant...|   false|The class discuss...|\n",
      "+------------+----------+--------------------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subdf = sqlsc.createDataFrame(subdf)\n",
    "subdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[u'class', u'work', u'load', u'writer'],\n",
       "   [u'quality', u'instruction', u'course', u'instructor', u'time'],\n",
       "   [u'paper', u'family', u'state'],\n",
       "   [u'lot', u'grader'],\n",
       "   [u'teacher', u'though\\\\xe2\\\\u20ac\\\\u201dhe'],\n",
       "   [u'course'],\n",
       "   [u'subject', u'course', u'overall', u'expectation'],\n",
       "   [u'purpose',\n",
       "    u'class',\n",
       "    u'freshman',\n",
       "    u'writing',\n",
       "    u'skill',\n",
       "    u'class',\n",
       "    u'resource',\n",
       "    u'purpose'],\n",
       "   [u'work', u'effort', u'essay'],\n",
       "   [u'essay', u'topic', u'guidance'],\n",
       "   [u'feedback', u'draft', u'draft'],\n",
       "   [u'feedback', u'office', u'hour'],\n",
       "   [u'peer', u'resource', u'guidance', u'class'],\n",
       "   [u'class', u'requirement'],\n",
       "   [u'lot', u'work', u'summary', u'assignment']],\n",
       "  [[u\"u'the\", u'high', u'helpful'],\n",
       "   [u'generous'],\n",
       "   [u'final'],\n",
       "   [u'u\"a', u'hard'],\n",
       "   [u'good', u'smart', u'nice'],\n",
       "   [u'unlikely'],\n",
       "   [u'passionate'],\n",
       "   [u'useful'],\n",
       "   [u'manageable'],\n",
       "   [u'reasonable', u'little'],\n",
       "   [u'vague', u'unhelpful', u'final'],\n",
       "   [u'difficult', u'constructive', u'accessible'],\n",
       "   [u'writing'],\n",
       "   [u'particular'],\n",
       "   [u'prepared', u'dense', u'philosophical', u'online']])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_parts = subdf.rdd.map(lambda r: get_parts(r.Comments))\n",
    "comment_parts.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 618 ms, sys: 151 ms, total: 769 ms\n",
      "Wall time: 7min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parsedcomments=comment_parts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin our text analysis with an LDA of the nouns in the comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'class', u'work', u'load', u'writer'],\n",
       "  [u'quality', u'instruction', u'course', u'instructor', u'time'],\n",
       "  [u'paper', u'family', u'state'],\n",
       "  [u'lot', u'grader'],\n",
       "  [u'teacher', u'though\\\\xe2\\\\u20ac\\\\u201dhe'],\n",
       "  [u'course'],\n",
       "  [u'subject', u'course', u'overall', u'expectation'],\n",
       "  [u'purpose',\n",
       "   u'class',\n",
       "   u'freshman',\n",
       "   u'writing',\n",
       "   u'skill',\n",
       "   u'class',\n",
       "   u'resource',\n",
       "   u'purpose'],\n",
       "  [u'work', u'effort', u'essay'],\n",
       "  [u'essay', u'topic', u'guidance'],\n",
       "  [u'feedback', u'draft', u'draft'],\n",
       "  [u'feedback', u'office', u'hour'],\n",
       "  [u'peer', u'resource', u'guidance', u'class'],\n",
       "  [u'class', u'requirement'],\n",
       "  [u'lot', u'work', u'summary', u'assignment']],\n",
       " [[u\"u'philosophy\",\n",
       "   u'stimulating',\n",
       "   u'class',\n",
       "   u'discussion',\n",
       "   u'variety',\n",
       "   u'topic',\n",
       "   u'student',\n",
       "   u'share'],\n",
       "  [u'state', u'philosophy', u'course', u'class'],\n",
       "  [u'lot', u'philosophy', u'professor', u'lot'],\n",
       "  [u'course', u'lot', u'reading', u'writing'],\n",
       "  [u'philosophy',\n",
       "   u'state',\n",
       "   u'discussion',\n",
       "   u'struggle',\n",
       "   u'balance',\n",
       "   u'nature',\n",
       "   u'society',\n",
       "   u'course'],\n",
       "  [u\"u'i\",\n",
       "   u'deal',\n",
       "   u'philosophy',\n",
       "   u'writing',\n",
       "   u'focus',\n",
       "   u'philosophy',\n",
       "   u'writing',\n",
       "   u'writing',\n",
       "   u'class'],\n",
       "  [u\"u'philosophy\", u'state', u'class', u'writing', u'essay', u'college'],\n",
       "  [u'matter', u'society'],\n",
       "  [u'page',\n",
       "   u'reading',\n",
       "   u'day',\n",
       "   u'syllabus',\n",
       "   u'warning',\n",
       "   u'thing',\n",
       "   u'tardiness',\n",
       "   u'grade'],\n",
       "  [u'fact'],\n",
       "  [u'course'],\n",
       "  [u'reading', u'understanding', u'work'],\n",
       "  [u'course'],\n",
       "  [u\"u'i\", u'page', u'entirety', u'work'],\n",
       "  [u'class', u'material', u'experience'],\n",
       "  [u'class', u'lot'],\n",
       "  [u'class', u'improvement', u'writing', u'understanding', u'writing'],\n",
       "  [u'u\"class', u'discussion', u'class', u'lot', u'philosophy'],\n",
       "  [u\"u'most\", u'student', u'class', u'philosophy', u'level', u'discussion'],\n",
       "  [u'class', u'philosophy', u'introduction', u'course', u'ton', u'student']],\n",
       " [[u'course'],\n",
       "  [u'kind', u'class'],\n",
       "  [u'decision', u'course'],\n",
       "  [u'end', u'man'],\n",
       "  [u'reading', u'kid'],\n",
       "  [u'section', u'discussion', u'time', u'topic', u'student', u'point', u'way'],\n",
       "  [u'philosophy'],\n",
       "  [u'downside', u'writing', u'component'],\n",
       "  [u'writer', u'measure'],\n",
       "  [u'time', u'class', u'lot', u'class', u'discussion'],\n",
       "  [u'teacher'],\n",
       "  [u'reading', u'understanding', u'philosophy'],\n",
       "  [u'day', u'material'],\n",
       "  [u'philosophy',\n",
       "   u'kind',\n",
       "   u'style',\n",
       "   u'lot',\n",
       "   u'definition',\n",
       "   u'introduction',\n",
       "   u'writing',\n",
       "   u'topic',\n",
       "   u'concern',\n",
       "   u'philosophy'],\n",
       "  [u'list', u'course'],\n",
       "  [u'reading', u'bit', u'time', u'reading', u'discussion'],\n",
       "  [u'way', u'government', u'philosopher', u'time'],\n",
       "  [u\"u'it\", u'class', u\"u'take\", u'class', u'philosophy', u'politic'],\n",
       "  [u'reading', u'discussion'],\n",
       "  [u'writing'],\n",
       "  [u\"u'very\", u'subject', u'matter', u'discussion'],\n",
       "  [u'man', u'teacher']]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e[0] for e in parsedcomments[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'class', u'work', u'load', u'writer'],\n",
       " [u'quality', u'instruction', u'course', u'instructor', u'time'],\n",
       " [u'paper', u'family', u'state'],\n",
       " [u'lot', u'grader'],\n",
       " [u'teacher', u'though\\\\xe2\\\\u20ac\\\\u201dhe']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldadatardd=sc.parallelize([ele[0] for ele in parsedcomments]).flatMap(lambda l: l)\n",
    "ldadatardd.cache()\n",
    "ldadatardd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'class', u'work', u'load', u'writer', u'quality']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldadatardd.flatMap(lambda word: word).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabtups = (ldadatardd.flatMap(lambda word: word)\n",
    "             .map(lambda word: (word, 1))\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "             .map(lambda (x,y): x)\n",
    "             .zipWithIndex()\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=vocabtups.collectAsMap()\n",
    "id2word=vocabtups.map(lambda (x,y): (y,x)).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'u\"byrne', u'post-grad', 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0], vocab.keys()[5], vocab[vocab.keys()[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12291"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def helperfunction(element):\n",
    "    d = defaultdict(int)\n",
    "    for k in element:\n",
    "        d[vocab[k]] += 1\n",
    "    return d.items()\n",
    "documents = ldadatardd.map(lambda w: helperfunction(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(737, 1), (1890, 1), (1982, 1), (3145, 1)],\n",
       " [(4488, 1), (954, 1), (11246, 1), (4902, 1), (5503, 1)],\n",
       " [(1688, 1), (4602, 1), (10135, 1)],\n",
       " [(9696, 1), (4435, 1)],\n",
       " [(3835, 1), (5557, 1)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus=documents.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda2 = gensim.models.ldamodel.LdaModel(corpus = corpus, num_topics = 2, id2word=id2word, chunksize=200, passes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we print the topics we find using LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.113*course + 0.054*material + 0.046*lecture + 0.024*way + 0.022*problem + 0.020*section + 0.018*exam + 0.014*student + 0.014*science + 0.012*requirement'),\n",
       " (1,\n",
       "  u'0.206*class + 0.052*lot + 0.040*time + 0.031*work + 0.029*professor + 0.021*topic + 0.019*reading + 0.018*fun + 0.018*u\"it + 0.012*assignment')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first topic (let us call this Topic 0) includes the combination of words: \n",
    "\n",
    "- class, lot, time, work, way, professor, problem, section, exam, and fun.\n",
    "\n",
    "\n",
    "The second topic (let us call this Topic 1) includes the following combination of words: \n",
    "\n",
    "- course, material, lecture, student, topic, reading, person, science, year, and lecturer.\n",
    "\n",
    "\n",
    "Topic 0 seems to encompass the more interactive, qualitative, personable aspects of the course with key terms including class, professor, problem, section, and fun. Topic 1, by contrast, seems to encompass the more solitary, logistical, factual aspects of a course that a student experiences with key terms including material, lecture, student, topic, reading, year, and lecturer. One thing worth noticing is that Topic 1 includes \"course\" as a key term while Topic 0 includes \"class\". While \"course\" and \"class\" are often used interchangably in language, \"class\" arguably connotes a more personal, interactive experience than \"course\", which is more administrative and logistical and more likely to be used as an umbrella term for everything from everyday class to homework. This would support our separation of Topic 0 and 1 into more interactive/personable aspects and more logistical/solitary aspects, respectively.\n",
    "\n",
    "In order to further evaluate our intial hypothesis that course reviews are split along two topics (interactive, qualitiative, personable aspects v. solitary, logistical aspects), we will output the words of some sentences, along with the probability of the sentence belonging to Topic 0 and Topic 1, to qualitatively check that our topics are reasonable and supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(737, 1), (1890, 1), (1982, 1), (3145, 1)]\n",
      "[(0, 0.10001293880410339), (1, 0.89998706119589666)]\n",
      "class writer load work\n",
      "==========================================\n",
      "[(3753, 1), (6562, 1)]\n",
      "[(0, 0.83332499701942198), (1, 0.16667500298057802)]\n",
      "concept background\n",
      "==========================================\n",
      "[(7218, 1)]\n",
      "[(0, 0.2500031236283346), (1, 0.74999687637166546)]\n",
      "reading\n",
      "==========================================\n",
      "[(4488, 1), (8096, 1), (2708, 1), (9767, 1)]\n",
      "[(0, 0.29956170591763021), (1, 0.70043829408236979)]\n",
      "time assignment philosophy night\n",
      "==========================================\n",
      "[(737, 1), (8153, 1), (1547, 1), (3145, 1)]\n",
      "[(0, 0.10002058584392144), (1, 0.89997941415607863)]\n",
      "class bit pass work\n",
      "==========================================\n",
      "[(4482, 1), (3908, 1), (9963, 1), (11729, 1), (8691, 1), (5977, 1)]\n",
      "[(0, 0.78528860947437507), (1, 0.21471139052562505)]\n",
      "thought-provoking discussion debate material staff teaching\n",
      "==========================================\n",
      "[(954, 1), (4435, 1)]\n",
      "[(0, 0.50000343897247579), (1, 0.49999656102752416)]\n",
      "course lot\n",
      "==========================================\n",
      "[(4488, 1), (8153, 1), (954, 1), (939, 1)]\n",
      "[(0, 0.35554611008604114), (1, 0.64445388991395891)]\n",
      "time bit course u\"must\n",
      "==========================================\n",
      "[(737, 1), (3811, 1), (4424, 1), (650, 1), (4364, 1), (8744, 1), (4435, 1), (4735, 1)]\n",
      "[(0, 0.40335797632525927), (1, 0.59664202367474073)]\n",
      "class cost intervention u'very benefit reform lot issue\n",
      "==========================================\n",
      "[(737, 1), (12066, 1), (8931, 1), (1750, 1), (10550, 1), (9111, 1), (954, 1), (11419, 1), (11966, 1)]\n",
      "[(0, 0.55395764437277162), (1, 0.44604235562722838)]\n",
      "class student success belief stand risk course question ability\n",
      "==========================================\n",
      "[(3008, 1), (5921, 1), (954, 1), (4435, 1), (4193, 1)]\n",
      "[(0, 0.58317216541170069), (1, 0.4168278345882992)]\n",
      "chance education course lot style\n",
      "==========================================\n",
      "[(12066, 1), (4746, 1)]\n",
      "[(0, 0.81608110542363022), (1, 0.18391889457636978)]\n",
      "student reason\n",
      "==========================================\n",
      "[(5668, 1), (954, 1), (3804, 1)]\n",
      "[(0, 0.6276027518819236), (1, 0.3723972481180764)]\n",
      "career course regret\n",
      "==========================================\n",
      "[(5921, 1), (7610, 1), (4435, 1), (9963, 1), (4633, 1)]\n",
      "[(0, 0.74986123585868025), (1, 0.2501387641413198)]\n",
      "education perspective lot debate history\n",
      "==========================================\n",
      "[(737, 1), (11042, 1)]\n",
      "[(0, 0.16699917888814811), (1, 0.83300082111185192)]\n",
      "class kink\n",
      "==========================================\n",
      "[(3680, 1), (377, 1), (737, 1), (3908, 1), (11729, 1)]\n",
      "[(0, 0.41666394337139961), (1, 0.58333605662860044)]\n",
      "way professor class discussion material\n",
      "==========================================\n",
      "[(3680, 1), (737, 1), (4213, 1), (3094, 1)]\n",
      "[(0, 0.69991655627237093), (1, 0.30008344372762907)]\n",
      "way class overview study\n",
      "==========================================\n",
      "[(4280, 1), (377, 1), (348, 1), (737, 1)]\n",
      "[(0, 0.11236883664282597), (1, 0.88763116335717407)]\n",
      "food professor person class\n",
      "==========================================\n",
      "[(737, 1), (1554, 1), (3908, 1), (12066, 1)]\n",
      "[(0, 0.4005557594982827), (1, 0.59944424050171718)]\n",
      "class section discussion student\n",
      "==========================================\n",
      "[(4488, 1), (11256, 1), (1730, 1)]\n",
      "[(0, 0.12500417631728131), (1, 0.87499582368271867)]\n",
      "time homework week\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "for bow in corpus[0:1200:60]:\n",
    "    print bow\n",
    "    print lda2.get_document_topics(bow)\n",
    "    print \" \".join([id2word[e[0]] for e in bow])\n",
    "    print \"==========================================\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"sentences\" (or bag-of-words) which have a much greater probability of belonging to Topic 0 include:\n",
    "- class writer load work\n",
    "- class bit pass work\n",
    "- class cost intervention u'very benefit reform lot issue\n",
    "- class student success belief stand risk course question ability\n",
    "- class kink\n",
    "- way professor class discussion material\n",
    "- food professor person class\n",
    "- class section discussion student\n",
    "- time homework week\n",
    "\n",
    "The words in these sentences are more descriptive and relate to more creative, interactive, person-to-person aspects of a course. Specifically, \"writer\", \"intervention\", \"reform\", \"issue\", \"success\", \"belief\", \"stand\", \"risk\", \"question\", \"kink\", and \"discussion\" all imply rich and diverse elements of the course experience. As a Harvard student, I know that the word \"section\" also implies discussion and collaboration since sections for Harvard classes provide an opportunity outside of lecture to engage more closely with course material and consist of tight-knit groups.\n",
    "\n",
    "\n",
    "The \"setences\" which have a much greater probability of belonging to Topic 1 include:\n",
    "- concept background\n",
    "- reading\n",
    "- thought-provoking discussion debate material staff teaching\n",
    "\n",
    "The function below transforms X-col (which consists of word-based \"sentences\" (bag-of-words or \"documents\")) using the vectorizer which is also a parameter.\n",
    "- time bit course u\"must\n",
    "- career course regret\n",
    "- education perspective lot debate history\n",
    "\n",
    "Words in these sentences that are not present in the previous cluster of setences and that stand out as implying more impersonal, logistical, or practical aspects of a course include \"concept\", \"background\", \"reading\", \"material\", \"time\", \"must\", \"education\", \"history\", and arguably \"staff\" (since \"staff\" is a somewhat impersonal way to refer to professors and teaching fellows). Although words like \"thought-provoking\", \"discussion\", \"debate\" and \"teaching\" do appear, it is worthwhile to note that the sentence/bag-of-words in which they appear still has a relatively high probability of belonging to Topic 0 (~35%).\n",
    "\n",
    "The \"sentences\" which have more equal probabilities of belonging to Topic 0 or 1 include:\n",
    "- time assignment philosophy night\n",
    "- course lot\n",
    "- chance education course lot style\n",
    "- student reason\n",
    "- way class overview study\n",
    "\n",
    "For sentences/bag-of-words with relatively equal probabilities of belonging to Topic 0 and Topic 1, we can observe both words implying more interactive, creative aspects (\"philosophy\", \"style\", \"student\", \"reason\") and words implying more logistical aspects (\"time\", \"assignment\", \"overview\", \"study\").\n",
    "\n",
    "\n",
    "From our analysis of the topic probabilities and bag-of-words above, there appears to be evidence to support our initial hypothesis that course reviews are split along two topics: Topic 0, which includes more interactive, qualitative, personable aspects of a course, and Topic 1, which includes more solitary, logistical aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DOs:\n",
    "- We can consider doing \"verbs\" (use TextBlob)\n",
    "- Detect \"not\" before adjectives, this shouldn't be too difficult\n",
    "- Text before pushing\n",
    "- Look at differences across departments (Jesse/Andrew)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us now continue with a sentiment analysis of the adjectives in the comments using Naive Bayes. We begin by extracting the adjectives as we did before with the nouns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u\"u'the\", u'high', u'helpful'],\n",
       "  [u'generous'],\n",
       "  [u'final'],\n",
       "  [u'u\"a', u'hard'],\n",
       "  [u'good', u'smart', u'nice'],\n",
       "  [u'unlikely'],\n",
       "  [u'passionate'],\n",
       "  [u'useful'],\n",
       "  [u'manageable'],\n",
       "  [u'reasonable', u'little'],\n",
       "  [u'vague', u'unhelpful', u'final'],\n",
       "  [u'difficult', u'constructive', u'accessible'],\n",
       "  [u'writing'],\n",
       "  [u'particular'],\n",
       "  [u'prepared', u'dense', u'philosophical', u'online']],\n",
       " [[u'wide', u'fellow', u'similar'],\n",
       "  [u'passionate', u'difficult', u'accurate'],\n",
       "  [u'interesting', u'great'],\n",
       "  [u'critical'],\n",
       "  [u'awesome'],\n",
       "  [u'great', u'political', u'different'],\n",
       "  [u'difficult', u'better'],\n",
       "  [u'subject', u'interesting'],\n",
       "  [u'dense', u'occasional', u'terrible'],\n",
       "  [u'terrifying'],\n",
       "  [u'interesting', u'intensive', u'difficult'],\n",
       "  [u'interesting',\n",
       "   u'mandatory',\n",
       "   u'solid',\n",
       "   u'important',\n",
       "   u'interesting',\n",
       "   u'philosophical'],\n",
       "  [u'good'],\n",
       "  [u'difficult', u'unnecessary'],\n",
       "  [u'potential', u'interesting'],\n",
       "  [u\"u'great\"],\n",
       "  [u'concrete', u'greater', u'effective'],\n",
       "  [u'interesting', u'willing', u'interesting'],\n",
       "  [u'high', u'engaging'],\n",
       "  [u'fellow']],\n",
       " [[u'favorite'],\n",
       "  [u'little', u'overwhelming'],\n",
       "  [u'rewarding'],\n",
       "  [u'scary'],\n",
       "  [u'heavy', u'interesting'],\n",
       "  [u'interesting', u'discussed', u'interesting', u'detailed'],\n",
       "  [u'political', u'acceptable'],\n",
       "  [u'major'],\n",
       "  [u'great'],\n",
       "  [u'large', u'outside', u'classic'],\n",
       "  [u'tough', u'fantastic'],\n",
       "  [u\"u'the\", u'great', u'political', u'better'],\n",
       "  [u'dense'],\n",
       "  [u'idiosyncratic', u'broader', u'academic'],\n",
       "  [u'reading', u'interesting'],\n",
       "  [u'expos', u'interesting', u'great'],\n",
       "  [u'great', u'greatest'],\n",
       "  [u'enlightening', u'interested', u'classic'],\n",
       "  [u'dense', u'interesting'],\n",
       "  [u'overwhelmed'],\n",
       "  [u'interesting', u'provocative'],\n",
       "  [u'excellent']]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbdatardd=sc.parallelize([ele[1] for ele in parsedcomments])\n",
    "nbdatardd.cache()\n",
    "nbdatardd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjvocabtups = (nbdatardd.flatMap(lambda l: l).flatMap(lambda word: word)\n",
    "             .map(lambda word: (word, 1))\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "             .map(lambda (x,y): x)\n",
    "             .zipWithIndex()\n",
    ").cache()\n",
    "adjvocab=adjvocabtups.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7945"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adjvocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to flatten the all of the adjectives for a particular semester of comments of a course into a single document and then make an array of these documents for get our adjective \"features\" and retrieve our response array, comprised of the positive column of our subdf, as this is the response variable we are trying to predict. The length of these two arrays should be equal if we do this correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "Xarraypre=nbdatardd.map(lambda l: \" \".join(list(itertools.chain.from_iterable(l))))\n",
    "Xarray=Xarraypre.collect()\n",
    "resparray = subdf.rdd.map(lambda r: r.Positive).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3279, 3279)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xarray), len(resparray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use mask to create a train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itrain, itest = train_test_split(xrange(len(Xarray)), train_size=0.7)\n",
    "mask=np.ones(len(Xarray), dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then transform the adjectives into a bag of words representation and use a vectorizer to create a feature and write some support functions for Naive Bayes analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_xy(X_col, y_col, vectorizer):\n",
    "    X = vectorizer.fit_transform(X_col)\n",
    "    y = y_col\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan on using log-likelyhood as a scoring metric and write a support function to be able to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(clf, x, y):\n",
    "    prob = clf.predict_log_proba(x)\n",
    "    negatives = y == False\n",
    "    positives = ~negatives\n",
    "    return prob[negatives, False].sum() + prob[positives, True].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to estimate the cross-validated score (given a classifier, data, and a scoring function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def cv_score(clf, x, y, score_func, nfold=5):\n",
    "    \"\"\"\n",
    "    Uses 5-fold cross validation to estimate a score of a classifier\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    clf : Classifier object\n",
    "    x : Input feature vector\n",
    "    y : Input class labels\n",
    "    score_func : Function like log_likelihood, that takes (clf, x, y) as input,\n",
    "                 and returns a score\n",
    "                 \n",
    "    Returns\n",
    "    -------\n",
    "    The average score obtained by splitting (x, y) into 5 folds of training and \n",
    "    test sets, fitting on the training set, and evaluating score_func on the test set\n",
    "    \n",
    "    Examples\n",
    "    cv_score(clf, x, y, log_likelihood)\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    for train, test in KFold(y.size, nfold): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf, x[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a usseful function for visualizing the calibration of a probabilistic classifier (in order to recognize whether our classifier is over-confident or under-confident)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibration_plot(clf, xtest, ytest):\n",
    "    prob = clf.predict_proba(xtest)[:, 1]\n",
    "    outcome = ytest\n",
    "    data = pd.DataFrame(dict(prob=prob, outcome=outcome))\n",
    "\n",
    "    #group outcomes into bins of similar probability\n",
    "    bins = np.linspace(0, 1, 20)\n",
    "    cuts = pd.cut(prob, bins)\n",
    "    binwidth = bins[1] - bins[0]\n",
    "    \n",
    "    #freshness ratio and number of examples in each bin\n",
    "    cal = data.groupby(cuts).outcome.agg(['mean', 'count'])\n",
    "    cal['pmid'] = (bins[:-1] + bins[1:]) / 2\n",
    "    cal['sig'] = np.sqrt(cal.pmid * (1 - cal.pmid) / cal['count'])\n",
    "        \n",
    "    #the calibration plot\n",
    "    ax = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "    p = plt.errorbar(cal.pmid, cal['mean'], cal['sig'])\n",
    "    plt.plot(cal.pmid, cal.pmid, linestyle='--', lw=1, color='k')\n",
    "    plt.ylabel(\"Empirical P(+)\")\n",
    "    \n",
    "    #the distribution of P(+)\n",
    "    ax = plt.subplot2grid((3, 1), (2, 0), sharex=ax)\n",
    "    \n",
    "    plt.bar(left=cal.pmid - binwidth / 2, height=cal['count'],\n",
    "            width=.95 * (bins[1] - bins[0]),\n",
    "            fc=p[0].get_color())\n",
    "    \n",
    "    plt.xlabel(\"Predicted P(+)\")\n",
    "    plt.ylabel(\"Number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
