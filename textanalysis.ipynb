{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curious Comments \n",
    "![commentpic](comment_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A critical part of any review are the comments. We will now proceed to analyze the comments in our q data. We will judge the predictive power of these comments, and analyze the role they play in a score's q rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import os\n",
    "import math\n",
    "from itertools import chain\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by creating a dataframe of comments. We will randomly subsample 10 comments per review and only consider courses 10 or more comments. Our dataframe will consist of three columns; Comment, Course and Overall Positive Rating. A course defined to have an 'Overall Positive Rating' if it has been been given more positive ratings than negative ratings across all semesters that it has been rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angela'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdf.head(6)\n",
    "t = [\"angela\",\"jeffrey\"]\n",
    "s = \"['angela','jeffrey']\"\n",
    "ast.literal_eval(s)\n",
    "ast.literal_eval(\"[\\\"\" + \"\\\",\\\"\".join(t) + \"\\\"]\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIN_PER_COURSESEM_REVIEWS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_Department</th>\n",
       "      <th>C_Number</th>\n",
       "      <th>Course</th>\n",
       "      <th>C_CatNum</th>\n",
       "      <th>C_ID</th>\n",
       "      <th>C_Semester</th>\n",
       "      <th>C_Year</th>\n",
       "      <th>C_Term</th>\n",
       "      <th>C_Overall</th>\n",
       "      <th>C_Workload</th>\n",
       "      <th>C_Difficulty</th>\n",
       "      <th>C_Recommendation</th>\n",
       "      <th>C_Enrollment</th>\n",
       "      <th>C_ResponseRate</th>\n",
       "      <th>I_First</th>\n",
       "      <th>I_Last</th>\n",
       "      <th>I_ID</th>\n",
       "      <th>I_Overall</th>\n",
       "      <th>I_EffectiveLectures</th>\n",
       "      <th>I_Accessible</th>\n",
       "      <th>I_GeneratesEnthusiasm</th>\n",
       "      <th>I_EncouragesParticipation</th>\n",
       "      <th>I_UsefulFeedback</th>\n",
       "      <th>I_ReturnsAssignmentsTimely</th>\n",
       "      <th>QOverall_1</th>\n",
       "      <th>QOverall_2</th>\n",
       "      <th>QOverall_3</th>\n",
       "      <th>QOverall_4</th>\n",
       "      <th>QOverall_5</th>\n",
       "      <th>QDifficulty_1</th>\n",
       "      <th>QDifficulty_2</th>\n",
       "      <th>QDifficulty_3</th>\n",
       "      <th>QDifficulty_4</th>\n",
       "      <th>QDifficulty_5</th>\n",
       "      <th>QWorkload_1</th>\n",
       "      <th>QWorkload_2</th>\n",
       "      <th>QWorkload_3</th>\n",
       "      <th>QWorkload_4</th>\n",
       "      <th>QWorkload_5</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sem_Average</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTSCI</td>\n",
       "      <td>270</td>\n",
       "      <td>HISTSCI-270</td>\n",
       "      <td>58523</td>\n",
       "      <td>2697</td>\n",
       "      <td>Spring '12</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6</td>\n",
       "      <td>50.00</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Lemov</td>\n",
       "      <td>79de794d3e2e19eb71a2033b0ec0b76d</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'This course is a perfect example of what gr...</td>\n",
       "      <td>4.226350</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '14</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4.10</td>\n",
       "      <td>7.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50</td>\n",
       "      <td>13</td>\n",
       "      <td>76.92</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'The class has a fairly high work load, but ...</td>\n",
       "      <td>4.244370</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '13</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.20</td>\n",
       "      <td>13</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'Philosophy of the State with Dr. Chen offer...</td>\n",
       "      <td>4.256888</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '12</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>3.73</td>\n",
       "      <td>2.47</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.47</td>\n",
       "      <td>15</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.64</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'This was by far my favorite course. Dr. Che...</td>\n",
       "      <td>4.190299</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXPOS</td>\n",
       "      <td>20.132</td>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>22108</td>\n",
       "      <td>1676</td>\n",
       "      <td>Fall '11</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.62</td>\n",
       "      <td>13</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Owen</td>\n",
       "      <td>Chen</td>\n",
       "      <td>1341ccb7bd27f47e68625b63b15281d1</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'Be prepared to read', u'Discussions were gr...</td>\n",
       "      <td>4.185893</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  C_Department C_Number        Course  C_CatNum  C_ID  C_Semester  C_Year  C_Term  C_Overall  C_Workload  C_Difficulty  C_Recommendation  C_Enrollment  C_ResponseRate  I_First I_Last                              I_ID  I_Overall  I_EffectiveLectures  I_Accessible  I_GeneratesEnthusiasm  I_EncouragesParticipation  I_UsefulFeedback  I_ReturnsAssignmentsTimely  QOverall_1  QOverall_2  QOverall_3  QOverall_4  QOverall_5  QDifficulty_1  QDifficulty_2  QDifficulty_3  QDifficulty_4  QDifficulty_5  \\\n",
       "0      HISTSCI      270   HISTSCI-270     58523  2697  Spring '12    2011       2       4.67        2.33          3.33              5.00             6           50.00  Rebecca  Lemov  79de794d3e2e19eb71a2033b0ec0b76d       4.67                 4.33          4.00                   4.33                       5.00              4.50                        4.00           0           0           0           1           2              0              0              2              1              0   \n",
       "1        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '14    2014       1       4.10        7.10           NaN              3.50            13           76.92     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       4.50                 4.60          3.70                   3.90                       3.90              4.10                        4.60           0           1           1           4           4              0              1              2              7              3   \n",
       "2        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '13    2013       1       3.50        2.60          3.90              3.20            13          100.00     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       3.80                 4.00          2.50                   3.50                       4.10              4.30                        4.40           0           1           1           4           4              0              1              2              7              3   \n",
       "3        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '12    2012       1       3.73        2.47          3.67              3.47            15          100.00     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       3.87                 4.33          2.64                   3.93                       4.18              3.64                        3.82           0           1           1           4           4              0              1              2              7              3   \n",
       "4        EXPOS   20.132  EXPOS-20.132     22108  1676    Fall '11    2011       1       3.85        2.00          3.54              3.62            13          100.00     Owen   Chen  1341ccb7bd27f47e68625b63b15281d1       4.08                 3.75          3.31                   3.92                       4.46              4.23                        4.08           0           1           1           4           4              0              1              2              7              3   \n",
       "\n",
       "   QWorkload_1  QWorkload_2  QWorkload_3  QWorkload_4  QWorkload_5                                           Comments  Sem_Average Positive  \n",
       "0            0            2            1            0            0  [u'This course is a perfect example of what gr...     4.226350     True  \n",
       "1            1            3            4            1            0  [u'The class has a fairly high work load, but ...     4.244370    False  \n",
       "2            1            3            4            1            0  [u'Philosophy of the State with Dr. Chen offer...     4.256888    False  \n",
       "3            1            3            4            1            0  [u'This was by far my favorite course. Dr. Che...     4.190299    False  \n",
       "4            1            3            4            1            0  [u'Be prepared to read', u'Discussions were gr...     4.185893    False  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdf=pd.read_csv(\"bigdf.csv\")\n",
    "bigdf.reset_index(drop=True)\n",
    "bigdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_comments(commentsListAsString):\n",
    "    if type(commentsListAsString) != str:\n",
    "        return \"\"\n",
    "    else:\n",
    "        allComments = ast.literal_eval(commentsListAsString)\n",
    "        if len(allComments) >= MIN_PER_COURSESEM_REVIEWS:\n",
    "            return \" \".join(np.random.choice(allComments, MIN_PER_COURSESEM_REVIEWS, replace=False))\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "subdf = bigdf[['Course','C_Semester','Comments', 'Positive']].dropna()\n",
    "subdf[\"Sampled_Comments\"] = subdf.Comments.map(sample_comments)\n",
    "subdf = subdf[subdf.Sampled_Comments != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course</th>\n",
       "      <th>C_Semester</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Sampled_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '14</td>\n",
       "      <td>[u'The class has a fairly high work load, but ...</td>\n",
       "      <td>False</td>\n",
       "      <td>I thoroughly enjoyed this course, but I know m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '13</td>\n",
       "      <td>[u'Philosophy of the State with Dr. Chen offer...</td>\n",
       "      <td>False</td>\n",
       "      <td>Class discussions are often very interesting b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '12</td>\n",
       "      <td>[u'This was by far my favorite course. Dr. Che...</td>\n",
       "      <td>False</td>\n",
       "      <td>If the reading list looks interesting, I highl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXPOS-20.132</td>\n",
       "      <td>Fall '11</td>\n",
       "      <td>[u'Be prepared to read', u'Discussions were gr...</td>\n",
       "      <td>False</td>\n",
       "      <td>This class is a challenge, but a challenge tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EXPOS-20.133</td>\n",
       "      <td>Spring '12</td>\n",
       "      <td>[u'This is a fantastic course if you have an i...</td>\n",
       "      <td>False</td>\n",
       "      <td>It would be very hard if you're not interested...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXPOS-20.133</td>\n",
       "      <td>Spring '14</td>\n",
       "      <td>[u'This is not a bad Expos course. Dr. Chen is...</td>\n",
       "      <td>False</td>\n",
       "      <td>This is not a bad Expos course. Dr. Chen is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '14</td>\n",
       "      <td>[u'If you are interested in political philosop...</td>\n",
       "      <td>False</td>\n",
       "      <td>The preceptor gives good feedback. - perhaps a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '13</td>\n",
       "      <td>[u'This class involves quite a bit of reading,...</td>\n",
       "      <td>False</td>\n",
       "      <td>Do not take this course. The readings are long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '12</td>\n",
       "      <td>[u\"A basic, but thorough, understanding of phi...</td>\n",
       "      <td>False</td>\n",
       "      <td>Although I had my doubts at first, this class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EXPOS-20.131</td>\n",
       "      <td>Fall '11</td>\n",
       "      <td>[u'It is a great class, which combines develop...</td>\n",
       "      <td>True</td>\n",
       "      <td>Be careful to give yourself adequate time for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EXPOS-20.134</td>\n",
       "      <td>Spring '12</td>\n",
       "      <td>[u\"It won't always be easy, but this class def...</td>\n",
       "      <td>False</td>\n",
       "      <td>It won't always be easy, but this class defini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EXPOS-20.134</td>\n",
       "      <td>Spring '14</td>\n",
       "      <td>[u\"The reading material is interesting and cha...</td>\n",
       "      <td>True</td>\n",
       "      <td>The reading material is interesting and challe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FRSEMR-38k</td>\n",
       "      <td>Fall '12</td>\n",
       "      <td>[u'An excellent seminar to learn a lot aout fi...</td>\n",
       "      <td>False</td>\n",
       "      <td>It can get boring at times; the subject matter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FRSEMR-38k</td>\n",
       "      <td>Fall '11</td>\n",
       "      <td>[u'This was the first year the seminar was off...</td>\n",
       "      <td>False</td>\n",
       "      <td>This class is extremely fun and creatively cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Course  C_Semester                                           Comments Positive                                   Sampled_Comments\n",
       "1   EXPOS-20.132    Fall '14  [u'The class has a fairly high work load, but ...    False  I thoroughly enjoyed this course, but I know m...\n",
       "2   EXPOS-20.132    Fall '13  [u'Philosophy of the State with Dr. Chen offer...    False  Class discussions are often very interesting b...\n",
       "3   EXPOS-20.132    Fall '12  [u'This was by far my favorite course. Dr. Che...    False  If the reading list looks interesting, I highl...\n",
       "4   EXPOS-20.132    Fall '11  [u'Be prepared to read', u'Discussions were gr...    False  This class is a challenge, but a challenge tha...\n",
       "6   EXPOS-20.133  Spring '12  [u'This is a fantastic course if you have an i...    False  It would be very hard if you're not interested...\n",
       "7   EXPOS-20.133  Spring '14  [u'This is not a bad Expos course. Dr. Chen is...    False  This is not a bad Expos course. Dr. Chen is a ...\n",
       "13  EXPOS-20.131    Fall '14  [u'If you are interested in political philosop...    False  The preceptor gives good feedback. - perhaps a...\n",
       "14  EXPOS-20.131    Fall '13  [u'This class involves quite a bit of reading,...    False  Do not take this course. The readings are long...\n",
       "15  EXPOS-20.131    Fall '12  [u\"A basic, but thorough, understanding of phi...    False  Although I had my doubts at first, this class ...\n",
       "16  EXPOS-20.131    Fall '11  [u'It is a great class, which combines develop...     True  Be careful to give yourself adequate time for ...\n",
       "19  EXPOS-20.134  Spring '12  [u\"It won't always be easy, but this class def...    False  It won't always be easy, but this class defini...\n",
       "20  EXPOS-20.134  Spring '14  [u\"The reading material is interesting and cha...     True  The reading material is interesting and challe...\n",
       "22    FRSEMR-38k    Fall '12  [u'An excellent seminar to learn a lot aout fi...    False  It can get boring at times; the subject matter...\n",
       "23    FRSEMR-38k    Fall '11  [u'This was the first year the seminar was off...    False  This class is extremely fun and creatively cha..."
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert our comments dataframe, subdf, to a spark dataframe for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vagrant/spark\n"
     ]
    }
   ],
   "source": [
    "#setup spark\n",
    "import os\n",
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()\n",
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"5g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "import sys\n",
    "rdd = sc.parallelize(xrange(10),10)\n",
    "rdd.map(lambda x: sys.version).collect()\n",
    "sys.version\n",
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$^&*+-|=~_')\n",
    "from sklearn.feature_extraction import text \n",
    "stopwords=text.ENGLISH_STOP_WORDS\n",
    "import re\n",
    "regex1=re.compile(r\"\\.{2,}\")\n",
    "regex2=re.compile(r\"\\-{2,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a get parts function to parse the language in the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parts(thetext):\n",
    "    thetext=re.sub(regex1, ' ', thetext)\n",
    "    thetext=re.sub(regex2, ' ', thetext)\n",
    "    nouns=[]\n",
    "    descriptives=[]\n",
    "    for i,sentence in enumerate(parse(thetext, tokenize=True, lemmata=True).split()):\n",
    "        nouns.append([])\n",
    "        descriptives.append([])\n",
    "        for token in sentence:\n",
    "            #print token\n",
    "            if len(token[4]) >0:\n",
    "                if token[1] in ['JJ', 'JJR', 'JJS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    descriptives[i].append(token[4])\n",
    "                elif token[1] in ['NN', 'NNS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    nouns[i].append(token[4])\n",
    "    out=zip(nouns, descriptives)\n",
    "    nouns2=[]\n",
    "    descriptives2=[]\n",
    "    for n,d in out:\n",
    "        if len(n)!=0 and len(d)!=0:\n",
    "            nouns2.append(n)\n",
    "            descriptives2.append(d)\n",
    "    return nouns2, descriptives2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------------------+\n",
      "|             Comment|      Course|Overall Positive Rating|\n",
      "+--------------------+------------+-----------------------+\n",
      "|The opportunity t...|RELIGION-98a|                   true|\n",
      "|This is an invalu...|RELIGION-98a|                   true|\n",
      "|Do your reading, ...|RELIGION-98a|                   true|\n",
      "|Excellent reading...|RELIGION-98a|                   true|\n",
      "|It's a thorough, ...|RELIGION-98a|                   true|\n",
      "+--------------------+------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subdf = sqlsc.createDataFrame(subdf)\n",
    "subdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[u'opportunity', u'tutorial', u'individual']],\n",
       "  [[u'one-on-one', u'incredible']]),\n",
       " ([[u'opportunity']], [[u'invaluable']]),\n",
       " ([], []),\n",
       " ([[u'reading', u'leader', u'reading', u'material']],\n",
       "  [[u'excellent', u'great', u'enjoyed']]),\n",
       " ([[u'way', u'dialogue', u'religion', u'science', u'regard', u'evolution']],\n",
       "  [[u'thorough', u'informative']])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_parts = subdf.rdd.map(lambda r: get_parts(r.Comment))\n",
    "comment_parts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 21.1 ms, total: 179 ms\n",
      "Wall time: 55.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parsedcomments=comment_parts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin our text analysis with an LDA of the nouns in the comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'opportunity', u'tutorial', u'individual']], [[u'opportunity']], []]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e[0] for e in parsedcomments[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'opportunity', u'tutorial', u'individual'],\n",
       " [u'opportunity'],\n",
       " [u'reading', u'leader', u'reading', u'material'],\n",
       " [u'way', u'dialogue', u'religion', u'science', u'regard', u'evolution'],\n",
       " [u'non-concentrator', u'class', u'religion']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldadatardd=sc.parallelize([ele[0] for ele in parsedcomments]).flatMap(lambda l: l)\n",
    "ldadatardd.cache()\n",
    "ldadatardd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'opportunity', u'tutorial', u'individual', u'opportunity', u'reading']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldadatardd.flatMap(lambda word: word).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabtups = (ldadatardd.flatMap(lambda word: word)\n",
    "             .map(lambda word: (word, 1))\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "             .map(lambda (x,y): x)\n",
    "             .zipWithIndex()\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=vocabtups.collectAsMap()\n",
    "id2word=vocabtups.map(lambda (x,y): (y,x)).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'req', u'dynasty', 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0], vocab.keys()[5], vocab[vocab.keys()[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3898"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def helperfunction(element):\n",
    "    d = defaultdict(int)\n",
    "    for k in element:\n",
    "        d[vocab[k]] += 1\n",
    "    return d.items()\n",
    "documents = ldadatardd.map(lambda w: helperfunction(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2464, 1), (682, 1), (781, 1)],\n",
       " [(682, 1)],\n",
       " [(2003, 1), (3742, 1), (1526, 2)],\n",
       " [(2085, 1), (1233, 1), (3850, 1), (1841, 1), (981, 1), (858, 1)],\n",
       " [(3360, 1), (981, 1), (3423, 1)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus=documents.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda2 = gensim.models.ldamodel.LdaModel(corpus = corpus, num_topics = 2, id2word=id2word, chunksize=200, passes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we print the topics we find using LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.129*course + 0.046*material + 0.026*lecture + 0.025*topic + 0.023*professor + 0.015*way + 0.014*history + 0.013*year + 0.012*problem + 0.011*question'),\n",
       " (1,\n",
       "  u'0.179*class + 0.043*lot + 0.031*student + 0.029*time + 0.025*work + 0.022*reading + 0.017*discussion + 0.016*paper + 0.015*fun + 0.014*research')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first topic (let us call this Topic 0) includes the combination of words: course, lot, material, time, way, work, experience, paper, field, and person. \n",
    "\n",
    "\n",
    "The second topic (let us call this Topic 1) includes the combination of words: class, course, student, professor, lecture, reading, history, topic, discussion, and fun.\n",
    "\n",
    "\n",
    "Topic 1 seems to encompass the more interactive, qualitative, personable aspects of the course with key terms including student, professor, discussion, lecture, and fun. Topic 0, by contrast, seems to encompass the more solitary, logistical, factual aspects of the course with key terms including material, time, work, experience, paper, and field. One thing worth noticing is that both topics include \"course\" as a key term but only Topic 1 includes \"class\". While \"course\" and \"class\" are often used interchangably in language, \"class\" arguably connotes a more personal, interactive experience than \"course\", which is more administrative and logistical and more likely to be used as an umbrella term for everything from everyday class to homework.\n",
    "\n",
    "\n",
    "In order to further evaluate our intial hypothesis that course reviews are split along two topics (interactive, qualitiative, personable aspects v. solitary, logistical aspects), we will output the words of some sentences, along with the probability of the sentence belonging to Topic 0 and Topic 1, to qualitatively check that our topics are reasonable and supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2464, 1), (682, 1), (781, 1)]\n",
      "[(0, 0.37402945436085688), (1, 0.62597054563914312)]\n",
      "individual opportunity tutorial\n",
      "==========================================\n",
      "[(929, 2), (2628, 1), (390, 2), (3718, 1), (2369, 1), (2775, 1), (3228, 1)]\n",
      "[(0, 0.70656544083864192), (1, 0.29343455916135819)]\n",
      "diet edge nutrition recommendation finding guideline math\n",
      "==========================================\n",
      "[(3225, 1), (1563, 1), (2575, 1)]\n",
      "[(0, 0.62695519457571203), (1, 0.37304480542428808)]\n",
      "lecture learning homework\n",
      "==========================================\n",
      "[(2563, 1)]\n",
      "[(0, 0.74986962180603833), (1, 0.25013037819396161)]\n",
      "instructor\n",
      "==========================================\n",
      "[(2297, 1), (514, 1), (459, 1), (1885, 1)]\n",
      "[(0, 0.8911380396522296), (1, 0.1088619603477704)]\n",
      "introduction linguist syntax field\n",
      "==========================================\n",
      "[(1368, 1), (3433, 1), (1475, 1), (2741, 1)]\n",
      "[(0, 0.32013442627167082), (1, 0.67986557372832912)]\n",
      "orgo undergrad enthusiasm step\n",
      "==========================================\n",
      "[(3360, 1), (2578, 1)]\n",
      "[(0, 0.16667798047327986), (1, 0.83332201952672014)]\n",
      "class fun\n",
      "==========================================\n",
      "[(2297, 1), (2851, 1), (1309, 1)]\n",
      "[(0, 0.62510619781304499), (1, 0.37489380218695495)]\n",
      "introduction department language\n",
      "==========================================\n",
      "[(403, 1)]\n",
      "[(0, 0.25015581326860203), (1, 0.74984418673139797)]\n",
      "seminar\n",
      "==========================================\n",
      "[(1448, 1), (3225, 1), (2685, 1), (2047, 1)]\n",
      "[(0, 0.65998378227465337), (1, 0.34001621772534663)]\n",
      "rambling lecture bit semester\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "for bow in corpus[0:1000:100]:\n",
    "    print bow\n",
    "    print lda2.get_document_topics(bow)\n",
    "    print \" \".join([id2word[e[0]] for e in bow])\n",
    "    print \"==========================================\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"sentences\" (or bag-of-words) which have a much greater probability of belonging to Topic 0 include:\n",
    "- field class thesis work\n",
    "- bit work lab\n",
    "- order course thing\n",
    "\n",
    "\n",
    "The words in these sentences relate to more impersonal, logistical aspects of a course. Specifically, \"field\", \"thesis\", \"work\", and \"order\" describe inflexible, solitary, requirement aspects of a course while \"bit\" and \"thing\" are more vague but nevertheless imply a degree of impartiability and detatchedness.\n",
    "\n",
    "\n",
    "\n",
    "The \"setences\" which have a much greater probability of belonging to Topic 1 include:\n",
    "- depth course grad class history student question\n",
    "- concept commitment moment life\n",
    "- section lecture exam reading drawback concept\n",
    "- class entertaining\n",
    "- evolution class pre cinema\n",
    "\n",
    "Words in these sentences that are not present in the previous cluster of setences and that stand out as implying more creative, interactive, person-to-person aspects of a course include \"depth\", \"history\", \"question\", \"concept\", \"commitment\", \"moment\", \"life\", \"drawback\", \"lecture\", and \"entertaining\". \n",
    "\n",
    "The \"sentences\" which have more equal probabilities of belonging to Topic 0 or 1 include:\n",
    "- lecture person\n",
    "- resource professor man kind topic\n",
    "\n",
    "We can observe words implying more logistical aspects (\"resource\", \"topic\") and more interactive, creative aspects (\"professor\", \"kind\"). \n",
    "\n",
    "\n",
    "Of course, words such as \"lecture\" can belong to either topic since lecture is both a logistical, required part of most courses and an engaging, potentially interactive opportunity for students to learn from professors. From our analysis of the topic probabilities and bag-of-words above, however, there appears to be evidence to support our initial hypothesis that course reviews are split along two topics: Topic 0, which includes more solitary, logistical aspects and Topic 1, which includes more interactive, qualitative, personable aspects of a course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DOs:\n",
    "- We can consider doing \"verbs\" (use TextBlob)\n",
    "- Detect \"not\" before adjectives, this shouldn't be too difficult\n",
    "- Text before pushing\n",
    "- Look at differences across departments (Jesse/Andrew)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
